{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a55fa5-4f80-4846-b713-dd9345eb2be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FINAL_FEATS: 20\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: Imports & Config ===\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "TIME_COL   = \"time\"\n",
    "PV_COL     = \"pv_id\"\n",
    "TARGET     = \"nins\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# âœ… ê³µì‹ ìµœì¢… í”¼ì²˜ 20ê°œ (ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "FINAL_FEATS = [\n",
    " 'humidity','wind_gust_spd','hour','doy','wind_spd_b',\n",
    " 'ceiling','uv_idx','appr_temp','uv_cloud_adj','dow',\n",
    " 'hour_sin','doy_sin','is_rain','rain','hour_cos',\n",
    " 'doy_cos','snow','coord1','coord2','haze'\n",
    "]\n",
    "\n",
    "MAX_GAP   = 12     # 5ë¶„ ê°„ê²© ê¸°ì¤€ 12ì¹¸ â‰ˆ 1ì‹œê°„\n",
    "DAY_HOURS = (6,18) # ì£¼ê°„ í”„ë¡ì‹œ(ë³´ê°„/í´ë¨í”„ì— ì‚¬ìš©)\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print(\"âœ… FINAL_FEATS:\", len(FINAL_FEATS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd67c20-d6e8-4aa7-a43b-31634bc16531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Time utils + time features ===\n",
    "def ensure_naive_datetime(s: pd.Series, tz=\"Asia/Seoul\") -> pd.Series:\n",
    "    if not is_datetime64_any_dtype(s):\n",
    "        s = pd.to_datetime(s, errors=\"coerce\", utc=True)\n",
    "    if isinstance(s.dtype, DatetimeTZDtype):\n",
    "        try:\n",
    "            s = s.dt.tz_convert(tz).dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            s = s.dt.tz_localize(None)\n",
    "    return s\n",
    "\n",
    "def cyclical_encode(series: pd.Series, period: int):\n",
    "    angle = 2*np.pi*(series.astype(\"float32\") % period)/period\n",
    "    return np.sin(angle).astype(\"float32\"), np.cos(angle).astype(\"float32\")\n",
    "\n",
    "def add_time_features(df: pd.DataFrame, time_col=TIME_COL) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[time_col] = ensure_naive_datetime(out[time_col])\n",
    "    out[\"hour\"] = out[time_col].dt.hour.astype(\"int16\")\n",
    "    out[\"dow\"]  = out[time_col].dt.dayofweek.astype(\"int8\")\n",
    "    out[\"doy\"]  = out[time_col].dt.dayofyear.astype(\"int16\")\n",
    "    out[\"hour_sin\"], out[\"hour_cos\"] = cyclical_encode(out[\"hour\"], 24)\n",
    "    out[\"doy_sin\"],  out[\"doy_cos\"]  = cyclical_encode(out[\"doy\"], 365)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e315bc-00a2-4d01-bcf4-46b04133878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Feature wrapper (ensure 20 feats exist) ===\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = add_time_features(df)\n",
    "\n",
    "    # is_rain\n",
    "    if \"is_rain\" not in out.columns:\n",
    "        src = \"rain\" if \"rain\" in out.columns else None\n",
    "        out[\"is_rain\"] = (pd.to_numeric(out[src], errors=\"coerce\").fillna(0) > 0).astype(\"int8\") if src else np.int8(0)\n",
    "\n",
    "    # haze (ê°€ì‹œê±°ë¦¬ ì—­ìˆ˜ í˜•íƒœê°€ ì—†ìœ¼ë©´ 0)\n",
    "    if \"haze\" not in out.columns:\n",
    "        out[\"haze\"] = np.float32(0.0)\n",
    "\n",
    "    # uv_cloud_adj (í´ë¼ìš°ë“œ ì—†ìœ¼ë©´ uv_idxë¡œ ëŒ€ì²´)\n",
    "    if \"uv_cloud_adj\" not in out.columns:\n",
    "        out[\"uv_cloud_adj\"] = pd.to_numeric(out.get(\"uv_idx\", 0.0), errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    # pv_id ì¹´í…Œê³ ë¦¬(ë©”ëª¨ë¦¬â†“)\n",
    "    if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n",
    "        out[PV_COL] = out[PV_COL].astype(\"category\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124fbf5b-b252-4bd0-b632-3641d0a9dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Interpolation (physics-aware, memory-light) ===\n",
    "def interpolate_weather(df: pd.DataFrame, max_gap: int=MAX_GAP) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    day_mask = out[\"hour\"].between(DAY_HOURS[0], DAY_HOURS[1])\n",
    "\n",
    "    # ì´ë²¤íŠ¸í˜•: is_rain (ë³´ê°„ X, ì§§ì€ ê²°ì†ë§Œ ë³´ì™„)\n",
    "    if \"is_rain\" in out.columns:\n",
    "        s = pd.to_numeric(out[\"is_rain\"], errors=\"coerce\")\n",
    "        s = out.groupby(PV_COL, observed=True)[\"is_rain\"].transform(lambda x: x.ffill().bfill()).astype(\"float32\")\n",
    "        for lev in ([\"pv_id\",\"hour\"], [\"pv_id\"]):\n",
    "            if s.isna().any():\n",
    "                s = s.fillna(out.groupby(lev, observed=True)[\"is_rain\"].transform(\"median\"))\n",
    "        out[\"is_rain\"] = s.fillna(0).astype(\"float32\")\n",
    "\n",
    "    # ì—°ì†í˜•: ì„ í˜•ë³´ê°„(uvëŠ” ì£¼ê°„ë§Œ), ì”ì—¬ëŠ” (pv,hour)->pv->ì „ì²´ ì¤‘ì•™ê°’\n",
    "    cont_cols = [c for c in [\"humidity\",\"wind_spd_b\",\"wind_gust_spd\",\"ceiling\",\"appr_temp\",\"uv_idx\",\"haze\"] if c in out.columns]\n",
    "    for c in cont_cols:\n",
    "        s = pd.to_numeric(out[c], errors=\"coerce\").astype(\"float32\")\n",
    "        if c == \"uv_idx\":\n",
    "            s = s.where(day_mask, 0.0)\n",
    "        s_lin = out.groupby(PV_COL, observed=True)[c].transform(\n",
    "            lambda x: x.interpolate(method=\"linear\", limit=max_gap, limit_direction=\"both\")\n",
    "        ).astype(\"float32\")\n",
    "        if s_lin.isna().any():\n",
    "            s_lin = s_lin.fillna(out.groupby([PV_COL,\"hour\"], observed=True)[c].transform(\"median\"))\n",
    "        if s_lin.isna().any():\n",
    "            s_lin = s_lin.fillna(out.groupby(PV_COL, observed=True)[c].transform(\"median\"))\n",
    "        out[c] = s_lin.fillna(s_lin.median()).astype(\"float32\")\n",
    "\n",
    "    # rain/snow: ë³´ê°„ ì—†ì´ 0 ì±„ì›€ + ë¬¼ë¦¬ì  í´ë¦½\n",
    "    for c in [\"rain\",\"snow\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\").fillna(0).clip(lower=0).astype(\"float32\")\n",
    "\n",
    "    # ë¬¼ë¦¬ ë²”ìœ„ í´ë¦½\n",
    "    clip_map = {\"humidity\":(0,100), \"uv_idx\":(0,None), \"wind_spd_b\":(0,None), \"wind_gust_spd\":(0,None),\n",
    "                \"ceiling\":(0,None), \"appr_temp\":(None,None), \"haze\":(0,None)}\n",
    "    for c,(lo,hi) in clip_map.items():\n",
    "        if c in out.columns:\n",
    "            x = out[c].astype(\"float32\")\n",
    "            if lo is not None: x = np.maximum(x, lo)\n",
    "            if hi is not None: x = np.minimum(x, hi)\n",
    "            out[c] = x.astype(\"float32\")\n",
    "\n",
    "    # uv_cloud_adj ê°±ì‹ (í´ë¼ìš°ë“œ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ)\n",
    "    if \"uv_idx\" in out.columns:\n",
    "        out[\"uv_cloud_adj\"] = pd.to_numeric(out.get(\"uv_cloud_adj\", out[\"uv_idx\"]), errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a46d56f-fa06-4a0d-a372-c3004c865274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train raw shape: (19236948, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_12772\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped NaN target rows: 0\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5: Load CSVs + basic FE ===\n",
    "train_raw = pd.read_csv(\"train.csv\", low_memory=True, memory_map=True)\n",
    "print(\"Train raw shape:\", train_raw.shape)\n",
    "train_raw = add_features(train_raw)\n",
    "\n",
    "# íƒ€ê¹ƒ ì •ì œ\n",
    "train_raw[TARGET] = pd.to_numeric(train_raw[TARGET], errors=\"coerce\").astype(\"float32\")\n",
    "before = len(train_raw); train_raw = train_raw.dropna(subset=[TARGET])\n",
    "print(f\"Dropped NaN target rows: {before - len(train_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e59c80c-49c8-444f-838f-278f71e7d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === G1: solar cosZ + uv soft clip ===\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def _deg2rad(x): return np.deg2rad(x).astype(\"float64\")\n",
    "\n",
    "def add_cosZ_safe(df, time_col=TIME_COL, lat_col=\"coord1\", lon_col=\"coord2\"):\n",
    "    out = df.copy()\n",
    "    # ì¤‘ë³µ ë°©ì§€\n",
    "    if \"cosZ\" in out.columns: out = out.drop(columns=[\"cosZ\",\"is_day\"], errors=\"ignore\")\n",
    "\n",
    "    t = pd.to_datetime(out[time_col], errors=\"coerce\")\n",
    "    lat = pd.to_numeric(out.get(lat_col, 36.5), errors=\"coerce\").fillna(36.5).astype(\"float64\")\n",
    "    lon = pd.to_numeric(out.get(lon_col, 127.9), errors=\"coerce\").fillna(127.9).astype(\"float64\")\n",
    "    n = t.dt.dayofyear.astype(\"int32\")\n",
    "    hour = t.dt.hour + t.dt.minute/60.0 + t.dt.second/3600.0\n",
    "\n",
    "    # ì ìœ„ ê·¼ì‚¬ + ì§€ì—­íƒœì–‘ì‹œ(KST=UTC+9)\n",
    "    delta = _deg2rad(23.44) * np.sin(_deg2rad(360.0*(284.0 + n)/365.0))\n",
    "    lst = hour + lon/15.0 - 9.0\n",
    "    H = _deg2rad(15.0 * (lst - 12.0))\n",
    "    phi = _deg2rad(lat)\n",
    "\n",
    "    cosZ = np.sin(phi)*np.sin(delta) + np.cos(phi)*np.cos(delta)*np.cos(H)\n",
    "    out[\"cosZ\"] = np.clip(cosZ, 0.0, None).astype(\"float32\")\n",
    "    out[\"is_day\"] = (out[\"cosZ\"] > 0).astype(\"int8\")\n",
    "\n",
    "    # ì—´ ì¤‘ë³µ ì „ë©´ ì œê±°(í˜¹ì‹œ ëª¨ë¥¼ 2ì¤‘ ìƒì„± ì˜ˆë°©)\n",
    "    out = out.loc[:, ~out.columns.duplicated()]\n",
    "    return out\n",
    "\n",
    "def clip_uv_idx_inplace(df, upper=6.0):\n",
    "    if \"uv_idx\" in df.columns:\n",
    "        df[\"uv_idx\"] = np.clip(pd.to_numeric(df[\"uv_idx\"], errors=\"coerce\").astype(\"float32\"), 0.0, float(upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a63b21a9-5c7a-49bb-88a3-af5e908095e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ ensure_naive_datetime ë¥¼ ì•„ë˜ë¡œ êµì²´\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "\n",
    "def ensure_naive_datetime(s: pd.Series, tz=\"Asia/Seoul\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    - ì´ë¯¸ datetime64[ns] (tz-naive): ê·¸ëŒ€ë¡œ ì‚¬ìš© (â–¶ ì ˆëŒ€ UTCë¡œ ì¬í•´ì„í•˜ì§€ ì•ŠìŒ)\n",
    "    - tz-aware: ì§€ì • tzë¡œ ë³€í™˜ í›„ tz ì œê±°\n",
    "    - ë¬¸ìì—´/ìˆ«ì: ë¡œì»¬ naiveë¡œ íŒŒì‹± (â–¶ utc=True ê¸ˆì§€)\n",
    "    \"\"\"\n",
    "    if is_datetime64_any_dtype(s):\n",
    "        # tz-aware ì¸ ê²½ìš°ë§Œ tz ì²˜ë¦¬\n",
    "        if isinstance(s.dtype, DatetimeTZDtype):\n",
    "            try:\n",
    "                s = s.dt.tz_convert(tz).dt.tz_localize(None)\n",
    "            except Exception:\n",
    "                s = s.dt.tz_localize(None)\n",
    "        return s\n",
    "    # ë¬¸ìì—´/ìˆ«ìëŠ” ë¡œì»¬ naiveë¡œ íŒŒì‹± (utc=False)\n",
    "    s = pd.to_datetime(s, errors=\"coerce\")  # <-- ì—¬ê¸°ì„œ utc=True ì“°ì§€ ì•ŠìŒ\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6205cf5f-93d3-483b-94c1-2166756fb489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_12772\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosZ>0 ratio: 0.5051853792578591\n",
      "corr(cosZ, nins): -0.466998638209336\n",
      "corr(cosZ, uv_idx): -0.5503545666788611\n",
      "night nins mean/median: 391.08160400390625 269.91497802734375\n",
      "day   nins mean/median: 100.32569122314453 0.0\n"
     ]
    }
   ],
   "source": [
    "# valid ì„¸íŠ¸ì—ì„œ í™•ì¸\n",
    "feats_t, use_tr, use_va = valid_time_split_with_cosZ(train_raw, uv_upper=6.0)\n",
    "\n",
    "print(\"cosZ>0 ratio:\", float((use_va[\"cosZ\"]>1e-4).mean()))\n",
    "print(\"corr(cosZ, nins):\", float(pd.Series(use_va[\"cosZ\"]).corr(use_va[TARGET])))\n",
    "if \"uv_idx\" in use_va.columns:\n",
    "    print(\"corr(cosZ, uv_idx):\", float(pd.Series(use_va[\"cosZ\"]).corr(use_va[\"uv_idx\"])))\n",
    "\n",
    "night = use_va[use_va[\"cosZ\"]<=1e-4]\n",
    "day   = use_va[use_va[\"cosZ\"]>1e-4]\n",
    "print(\"night nins mean/median:\", float(night[TARGET].mean()), float(night[TARGET].median()))\n",
    "print(\"day   nins mean/median:\", float(day[TARGET].mean()),   float(day[TARGET].median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c39eb1a-7e46-4eda-948a-a2c783f6b3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Start grid sweep (uv_upper Ã— blend_coef)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_12772\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[uv_upper=5.0 | blend_coef=0.25]  base=69.3240  blend=210.2521\n",
      "[uv_upper=5.0 | blend_coef=0.35]  base=69.3240  blend=210.2374\n",
      "[uv_upper=5.0 | blend_coef=0.45]  base=69.3240  blend=210.2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_12772\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸš€ Start grid sweep (uv_upper Ã— blend_coef)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m U \u001b[38;5;129;01min\u001b[39;00m grid_uv:\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# 1) ì‹œê°„ í™€ë“œì•„ì›ƒ ë¶„í•  + ì„¸íŠ¸ë³„ ë³´ê°„ + uv clip(U)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     feats_t, use_tr, use_va = \u001b[43mvalid_time_split_with_cosZ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muv_upper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# 2) ë² ì´ìŠ¤ ëª¨ë¸ í•™ìŠµ(ì¡°ê¸°ì¢…ë£Œ)\u001b[39;00m\n\u001b[32m     24\u001b[39m     dtr = xgb.DMatrix(use_tr[feats_t], label=use_tr[\u001b[33m\"\u001b[39m\u001b[33mnins\u001b[39m\u001b[33m\"\u001b[39m].values, feature_names=feats_t)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mvalid_time_split_with_cosZ\u001b[39m\u001b[34m(train_raw, uv_upper)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalid_time_split_with_cosZ\u001b[39m(train_raw, uv_upper=\u001b[32m6.0\u001b[39m):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# 1) íŒŒìƒ\u001b[39;00m\n\u001b[32m      9\u001b[39m     df = add_features(train_raw)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     df = \u001b[43madd_cosZ_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# 2) ì„¸íŠ¸ ë¶„í• (ì‹œê°„)\u001b[39;00m\n\u001b[32m     12\u001b[39m     df_tr, df_va = time_holdout(df, frac=\u001b[32m0.2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36madd_cosZ_safe\u001b[39m\u001b[34m(df, time_col, lat_col, lon_col)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcosZ\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m out.columns: out = out.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mcosZ\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mis_day\u001b[39m\u001b[33m\"\u001b[39m], errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m t = pd.to_datetime(out[time_col], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m lat = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m36.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m36.5\u001b[39;49m\u001b[43m)\u001b[49m.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m lon = pd.to_numeric(out.get(lon_col, \u001b[32m127.9\u001b[39m), errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m).fillna(\u001b[32m127.9\u001b[39m).astype(\u001b[33m\"\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m n = t.dt.dayofyear.astype(\u001b[33m\"\u001b[39m\u001b[33mint32\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\generic.py:7372\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, method, axis, inplace, limit, downcast)\u001b[39m\n\u001b[32m   7365\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   7367\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m parameter must be a scalar, dict \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7368\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor Series, but you passed a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   7369\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7370\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m7372\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast\u001b[49m\n\u001b[32m   7374\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7376\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n\u001b[32m   7377\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\base.py:186\u001b[39m, in \u001b[36mDataManager.fillna\u001b[39m\u001b[34m(self, value, limit, inplace, downcast)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[32m    184\u001b[39m     limit = libalgos.validate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit=limit)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfillna\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1729\u001b[39m, in \u001b[36mBlock.fillna\u001b[39m\u001b[34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[39m\n\u001b[32m   1727\u001b[39m     noop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1729\u001b[39m     mask = \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1730\u001b[39m     mask, noop = validate_putmask(\u001b[38;5;28mself\u001b[39m.values, mask)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m noop:\n\u001b[32m   1733\u001b[39m     \u001b[38;5;66;03m# we can't process the value, but nothing to do\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[39m, in \u001b[36misna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:207\u001b[39m, in \u001b[36m_isna\u001b[39m\u001b[34m(obj, inf_as_na)\u001b[39m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np.ndarray, ABCExtensionArray)):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._can_hold_na:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:300\u001b[39m, in \u001b[36m_isna_array\u001b[39m\u001b[34m(values, inf_as_na)\u001b[39m\n\u001b[32m    298\u001b[39m         result = ~np.isfinite(values)\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m         result = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === GRID: uv_upper Ã— blend_coef (9ì¡°í•©) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# ì•ˆì „ì¥ì¹˜: í•„ìš”í•œ ì „ì—­ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ë¡œ ì•Œë ¤ì¤Œ\n",
    "assert \"train_raw\" in globals(), \"train_rawê°€ ì—†ìŠµë‹ˆë‹¤. (Cell 5ì—ì„œ train.csv ë¡œë“œ í•„ìš”)\"\n",
    "assert \"valid_time_split_with_cosZ\" in globals(), \"valid_time_split_with_cosZ í•¨ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. (G2 ì…€ ì‹¤í–‰)\"\n",
    "assert \"fit_day_aux_and_blend\" in globals(), \"fit_day_aux_and_blend í•¨ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. (ë¸”ë Œë”© íŒ¨ì¹˜ ì…€ ì‹¤í–‰)\"\n",
    "assert \"params2\" in globals(), \"params2ê°€ ì—†ìŠµë‹ˆë‹¤. (G2 ì…€ì—ì„œ params2 ì •ì˜)\"\n",
    "\n",
    "grid_uv = [5.0, 6.0, 7.0]\n",
    "grid_b  = [0.25, 0.35, 0.45]\n",
    "\n",
    "best = None  # (blend_mae, base_mae, U, b, bst2, feats_t, use_tr, use_va, aux_model)\n",
    "\n",
    "print(\"ğŸš€ Start grid sweep (uv_upper Ã— blend_coef)\")\n",
    "for U in grid_uv:\n",
    "    # 1) ì‹œê°„ í™€ë“œì•„ì›ƒ ë¶„í•  + ì„¸íŠ¸ë³„ ë³´ê°„ + uv clip(U)\n",
    "    feats_t, use_tr, use_va = valid_time_split_with_cosZ(train_raw, uv_upper=U)\n",
    "\n",
    "    # 2) ë² ì´ìŠ¤ ëª¨ë¸ í•™ìŠµ(ì¡°ê¸°ì¢…ë£Œ)\n",
    "    dtr = xgb.DMatrix(use_tr[feats_t], label=use_tr[\"nins\"].values, feature_names=feats_t)\n",
    "    dva = xgb.DMatrix(use_va[feats_t], label=use_va[\"nins\"].values, feature_names=feats_t)\n",
    "\n",
    "    bst2 = xgb.train(params2, dtr, num_boost_round=3000,\n",
    "                     evals=[(dtr, \"train\"), (dva, \"valid\")],\n",
    "                     early_stopping_rounds=200, verbose_eval=False)\n",
    "    base_pred = bst2.predict(dva, iteration_range=(0, bst2.best_iteration + 1)).astype(\"float32\")\n",
    "    base_mae  = mean_absolute_error(use_va[\"nins\"].values, base_pred)\n",
    "\n",
    "    for b in grid_b:\n",
    "        # 3) ë‚®-ì „ìš© ë³´ì¡°ëª¨ë¸ í•™ìŠµ + ë¸”ë Œë”©(ì¸ë±ìŠ¤ ì •ë ¬ ì•ˆì „ ë²„ì „)\n",
    "        aux_model, pred_blend, mae_blend = fit_day_aux_and_blend(\n",
    "            use_tr, use_va, feats_t, params2, bst2.best_iteration + 1, bst2, blend_coef=b\n",
    "        )\n",
    "        print(f\"[uv_upper={U:.1f} | blend_coef={b:.2f}]  base={base_mae:.4f}  blend={mae_blend:.4f}\")\n",
    "\n",
    "        if (best is None) or (mae_blend < best[0]):\n",
    "            best = (mae_blend, base_mae, U, b, bst2, feats_t, use_tr, use_va, aux_model)\n",
    "\n",
    "print(\"\\nğŸ¯ [GRID BEST]\")\n",
    "print(\"blend_MAE=%.4f (base=%.4f) | uv_upper=%.1f | blend_coef=%.2f | best_iter=%d | feats=%d\"\n",
    "      % (best[0], best[1], best[2], best[3], best[4].best_iteration + 1, len(best[5])))\n",
    "\n",
    "# ì„ íƒ: ë² ìŠ¤íŠ¸ êµ¬ì„± ê°ì²´ë¥¼ ë³€ìˆ˜ë¡œ ë‚¨ê²¨ë‘ë©´ ì´í›„ G4/G5ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥\n",
    "BEST_BLEND_MAE, BEST_BASE_MAE, UV_BEST, B_COEF_BEST, BST2_BEST, FEATS_BEST, TR_BEST, VA_BEST, AUX_BEST = best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd0304-44ed-4712-9676-05483dca79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_categorical_dtype ê²½ê³  íŒ¨ì¹˜\n",
    "from pandas.api.types import CategoricalDtype\n",
    "if PV_COL in out.columns and not isinstance(out[PV_COL].dtype, CategoricalDtype):\n",
    "    out[PV_COL] = out[PV_COL].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4329955-4989-4ed1-9139-b298153c2c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78f0704-604f-4674-bcb0-1a3a34dff552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_12772\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Re-VALID (time holdout + cosZ + uv_clip)â€¦\n",
      "[0]\ttrain-mae:226.46309\tvalid-mae:249.89199\n",
      "[300]\ttrain-mae:44.55503\tvalid-mae:70.34930\n",
      "[396]\ttrain-mae:43.19719\tvalid-mae:70.84254\n",
      "âœ… VALID (time) MAE=68.6139 | it=197 | feats=21\n"
     ]
    }
   ],
   "source": [
    "# === G2: time holdout valid with cosZ + uv clip + stronger reg ===\n",
    "def time_holdout(df, frac=0.2):\n",
    "    df = df.sort_values(TIME_COL)\n",
    "    n = len(df); n_va = max(1, int(n*frac))\n",
    "    return df.iloc[:-n_va].copy(), df.iloc[-n_va:].copy()\n",
    "\n",
    "def valid_time_split_with_cosZ(train_raw, uv_upper=6.0):\n",
    "    # 1) íŒŒìƒ\n",
    "    df = add_features(train_raw)\n",
    "    df = add_cosZ_safe(df)\n",
    "    # 2) ì„¸íŠ¸ ë¶„í• (ì‹œê°„)\n",
    "    df_tr, df_va = time_holdout(df, frac=0.2)\n",
    "    # 3) ë³´ê°„(ì„¸íŠ¸ë³„ë¡œ ë”°ë¡œ) + uv ì†Œí”„íŠ¸í´ë¦½\n",
    "    df_tr = interpolate_weather(df_tr, max_gap=MAX_GAP); clip_uv_idx_inplace(df_tr, uv_upper)\n",
    "    df_va = interpolate_weather(df_va, max_gap=MAX_GAP); clip_uv_idx_inplace(df_va, uv_upper)\n",
    "    # 4) í”¼ì²˜ì…‹(20ê°œ + cosZ)\n",
    "    feats = [c for c in FINAL_FEATS if c in df_tr.columns]\n",
    "    if \"cosZ\" in df_tr.columns: feats = feats + ([\"cosZ\"] if \"cosZ\" not in feats else [])\n",
    "    # 5) ì •ë¦¬\n",
    "    use_tr = df_tr[feats + [TARGET]].dropna().copy()\n",
    "    use_va = df_va[feats + [TARGET]].dropna().copy()\n",
    "    use_tr[feats] = use_tr[feats].astype(\"float32\")\n",
    "    use_va[feats] = use_va[feats].astype(\"float32\")\n",
    "    return feats, use_tr, use_va\n",
    "\n",
    "feats_t, use_tr, use_va = valid_time_split_with_cosZ(train_raw, uv_upper=6.0)\n",
    "dtr = xgb.DMatrix(use_tr[feats_t], label=use_tr[TARGET].values, feature_names=feats_t)\n",
    "dva = xgb.DMatrix(use_va[feats_t], label=use_va[TARGET].values, feature_names=feats_t)\n",
    "\n",
    "# ì •ê·œí™” ì¡°ê¸ˆ ê°•í™”(ê¹Šì´â†“, colsampleâ†‘, lr=0.05)\n",
    "params2 = {\n",
    "    \"objective\": \"reg:squarederror\", \"eval_metric\": \"mae\",\n",
    "    \"learning_rate\": 0.05, \"max_depth\": 7, \"min_child_weight\": 3,\n",
    "    \"subsample\": 0.85, \"colsample_bytree\": 0.90,\n",
    "    \"reg_alpha\": 0.3, \"reg_lambda\": 1.0,\n",
    "    \"random_state\": RANDOM_SEED,\n",
    "}\n",
    "\n",
    "print(\"ğŸš€ Re-VALID (time holdout + cosZ + uv_clip)â€¦\")\n",
    "bst2 = xgb.train(params2, dtr, num_boost_round=3000,\n",
    "                 evals=[(dtr,\"train\"),(dva,\"valid\")],\n",
    "                 early_stopping_rounds=200, verbose_eval=300)\n",
    "best2 = bst2.best_iteration + 1\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "val2 = mean_absolute_error(use_va[TARGET].values,\n",
    "                           bst2.predict(dva, iteration_range=(0, bst2.best_iteration+1)).astype(\"float32\"))\n",
    "print(f\"âœ… VALID (time) MAE={val2:.4f} | it={best2} | feats={len(feats_t)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b852e1-5431-4887-b8ac-983a613c8866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ VALID (blend) MAE=210.2540  vs base 68.6139\n"
     ]
    }
   ],
   "source": [
    "# === G3: day-only aux model + soft blend on validation ===\n",
    "def fit_day_aux_and_blend(use_tr, use_va, feats, base_params, base_best_iter):\n",
    "    # ë‚®/ë°¤ ë¶„ë¦¬ ê¸°ì¤€ (ì™„ì „í•œ ë°¤ì€ 0, ë¯¸ì„¸ ìƒˆë²½/í•´ì§ˆë…˜ì€ ì•½í•œ ê°€ì¤‘)\n",
    "    eps = 1e-4\n",
    "    tr_day = use_tr[use_tr[\"cosZ\"] > eps].copy()\n",
    "    va_day = use_va[use_va[\"cosZ\"] > eps].copy()\n",
    "    va_all = use_va.copy()\n",
    "\n",
    "    # A) ë² ì´ìŠ¤ ëª¨ë¸(bst2) ì´ë¯¸ ìˆìœ¼ë‹ˆ ì˜ˆì¸¡ í™•ë³´\n",
    "    pred_base = bst2.predict(xgb.DMatrix(va_all[feats], feature_names=feats)).astype(\"float32\")\n",
    "    pred_base = np.clip(pred_base, 0, None)\n",
    "\n",
    "    # B) ë‚® ì „ìš© ë³´ì¡° ëª¨ë¸(ê°™ì€ íŒŒë¼ë¯¸í„°, ë°˜ë³µìˆ˜ëŠ” base_best_iter*0.8)\n",
    "    n_boost_aux = max(600, int(base_best_iter*0.8))\n",
    "    dtr_day = xgb.DMatrix(tr_day[feats], label=tr_day[TARGET].values, feature_names=feats)\n",
    "    dva_day = xgb.DMatrix(va_day[feats], label=va_day[TARGET].values, feature_names=feats)\n",
    "    aux = xgb.train(base_params, dtr_day, num_boost_round=n_boost_aux,\n",
    "                    evals=[(dtr_day,\"train\")], verbose_eval=False)\n",
    "\n",
    "    # C) ë¸”ë Œë”©: cosZ-ê°€ì¤‘(ë¶€ë“œëŸ½ê²Œ) â€” cosZê°€ í´ìˆ˜ë¡ aux ë¹„ì¤‘â†‘\n",
    "    pred_aux_day = aux.predict(dva_day).astype(\"float32\")\n",
    "    pred_aux_day = np.clip(pred_aux_day, 0, None)\n",
    "\n",
    "    out = pred_base.copy()\n",
    "    w = np.clip(va_day[\"cosZ\"].values, 0.0, 1.0).astype(\"float32\")  # 0~1\n",
    "    blend_day = (1.0 - 0.35*w) * pred_base[va_all[\"cosZ\"].values>eps] + (0.35*w) * pred_aux_day\n",
    "    out[va_all[\"cosZ\"].values>eps] = blend_day\n",
    "\n",
    "    # ì™„ì „í•œ ë°¤ì€ 0ìœ¼ë¡œ ë³´ìˆ˜ì  ì²˜ë¦¬\n",
    "    out[va_all[\"cosZ\"].values<=eps] = 0.0\n",
    "    mae_all = float(np.mean(np.abs(out - va_all[TARGET].values)))\n",
    "    return aux, out, mae_all\n",
    "\n",
    "aux_model, pred_blend, mae_blend = fit_day_aux_and_blend(use_tr, use_va, feats_t, params2, best2)\n",
    "print(f\"âœ¨ VALID (blend) MAE={mae_blend:.4f}  vs base {val2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54769ad-fc75-4296-9bf7-ec8ee62b2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === G4: Full-data train for both models ===\n",
    "# ì „ì²´ ë°ì´í„°ë¡œ ë‹¤ì‹œ ì„¸íŒ…\n",
    "feats_full, full_tr, _ = valid_time_split_with_cosZ(train_raw, uv_upper=6.0)\n",
    "d_full = xgb.DMatrix(full_tr[feats_full], label=full_tr[TARGET].values, feature_names=feats_full)\n",
    "\n",
    "# ë² ì´ìŠ¤(ì „ì²´) â€” ê²€ì¦ best ë°˜ë³µìˆ˜ë³´ë‹¤ ì‚´ì§ ë„‰ë„‰í•˜ê²Œ\n",
    "num_round_base = max(1400, int(best2*1.15))\n",
    "base_full = xgb.train(params2, d_full, num_boost_round=num_round_base, verbose_eval=300)\n",
    "base_full.save_model(\"xgb_base_full.json\")\n",
    "\n",
    "# ë‚®ì „ìš©\n",
    "tr_day_full = full_tr[full_tr[\"cosZ\"] > 1e-4].copy()\n",
    "d_day_full  = xgb.DMatrix(tr_day_full[feats_full], label=tr_day_full[TARGET].values, feature_names=feats_full)\n",
    "num_round_aux = max(800, int(best2*0.9))\n",
    "aux_full = xgb.train(params2, d_day_full, num_boost_round=num_round_aux, verbose_eval=300)\n",
    "aux_full.save_model(\"xgb_aux_day_full.json\")\n",
    "\n",
    "print(\"ğŸ’¾ Saved: xgb_base_full.json, xgb_aux_day_full.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595dd310-ce73-48d9-a647-686087423220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === G5: Test predict with soft blend & night rule ===\n",
    "TEST_CSV = \"test.csv\"\n",
    "SUB_CSV  = \"submission_sample.csv\" if os.path.exists(\"submission_sample.csv\") else \"sample_submission.csv\"\n",
    "\n",
    "test_raw = pd.read_csv(TEST_CSV, low_memory=True, memory_map=True)\n",
    "test_raw = add_features(test_raw)\n",
    "test_raw = add_cosZ_safe(test_raw)\n",
    "\n",
    "test_itp = interpolate_weather(test_raw, max_gap=MAX_GAP)\n",
    "clip_uv_idx_inplace(test_itp, upper=6.0)\n",
    "\n",
    "feat_exist = [c for c in feats_full if c in test_itp.columns]\n",
    "X_te = test_itp[feat_exist].astype(\"float32\").fillna(0)\n",
    "\n",
    "dte = xgb.DMatrix(X_te, feature_names=feat_exist)\n",
    "pred_base = base_full.predict(dte).astype(\"float32\"); pred_base = np.clip(pred_base, 0, None)\n",
    "\n",
    "# ë‚®ì „ìš© ë³´ì¡°\n",
    "mask_day = (test_itp[\"cosZ\"].values > 1e-4)\n",
    "pred_out = pred_base.copy()\n",
    "if mask_day.any():\n",
    "    dte_day = xgb.DMatrix(X_te.loc[mask_day], feature_names=feat_exist)\n",
    "    pred_aux = aux_full.predict(dte_day).astype(\"float32\"); pred_aux = np.clip(pred_aux, 0, None)\n",
    "    w = np.clip(test_itp.loc[mask_day, \"cosZ\"].values, 0.0, 1.0).astype(\"float32\")\n",
    "    pred_out[mask_day] = (1.0 - 0.35*w) * pred_base[mask_day] + (0.35*w) * pred_aux\n",
    "\n",
    "# ì™„ì „í•œ ë°¤ì€ 0ìœ¼ë¡œ\n",
    "pred_out[~mask_day] = 0.0\n",
    "\n",
    "# ì œì¶œ ë³‘í•©\n",
    "sub = pd.read_csv(SUB_CSV)\n",
    "if len(sub) == len(pred_out):\n",
    "    sub[\"nins\"] = pred_out\n",
    "else:\n",
    "    merge_keys = [k for k in [\"time\",\"pv_id\",\"type\"] if k in sub.columns and k in test_raw.columns]\n",
    "    for df_ in (sub, test_raw):\n",
    "        if \"time\" in df_.columns:\n",
    "            df_[\"time\"] = pd.to_datetime(df_[\"time\"], errors=\"coerce\")\n",
    "    ref = test_raw[merge_keys].copy(); ref[\"nins\"] = pred_out\n",
    "    sub = sub.drop(columns=[\"nins\"], errors=\"ignore\").merge(ref, on=merge_keys, how=\"left\")\n",
    "\n",
    "sub[\"nins\"] = sub[\"nins\"].fillna(0).astype(\"float32\")\n",
    "sub.to_csv(\"result_submission.csv\", index=False)\n",
    "print(\"âœ… Saved: result_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e7680-53fb-4a62-bf35-0997eb38f572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95385a2c-3c8c-4262-a5ea-3d465651f625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185741f4-5371-4074-9735-1785d7e6c051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57addf2a-b233-4ed9-8b6a-8e53b4ca5ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9294192-52dc-4903-a0fd-be90af64c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split â†’ (15389558, 20) (3847390, 20)\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6: Split â†’ Interp per set (no leakage) ===\n",
    "train_df, valid_df = train_test_split(train_raw, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "train_df = interpolate_weather(train_df, max_gap=MAX_GAP)\n",
    "valid_df = interpolate_weather(valid_df, max_gap=MAX_GAP)\n",
    "\n",
    "# í•„ìš”í•œ ì—´ë§Œ ì–‡ê²Œ + NaN 0 ëŒ€ì²´\n",
    "use_cols_tr = [c for c in (FINAL_FEATS + [TARGET]) if c in train_df.columns]\n",
    "use_cols_va = [c for c in (FINAL_FEATS + [TARGET]) if c in valid_df.columns]\n",
    "train_df = train_df[use_cols_tr].copy()\n",
    "valid_df = valid_df[use_cols_va].copy()\n",
    "train_df[FINAL_FEATS] = train_df[FINAL_FEATS].astype(\"float32\").fillna(0)\n",
    "valid_df[FINAL_FEATS] = valid_df[FINAL_FEATS].astype(\"float32\").fillna(0)\n",
    "\n",
    "X_tr, y_tr = train_df[FINAL_FEATS], train_df[TARGET].values\n",
    "X_va, y_va = valid_df[FINAL_FEATS], valid_df[TARGET].values\n",
    "print(\"Split â†’\", X_tr.shape, X_va.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13ac2e8-9d6a-4ab5-b5cd-6d67cb5e15bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Training...\n",
      "[0]\ttrain-mae:234.22506\tvalid-mae:234.21788\n",
      "[200]\ttrain-mae:55.90217\tvalid-mae:55.96908\n",
      "[400]\ttrain-mae:50.20126\tvalid-mae:50.36508\n",
      "[600]\ttrain-mae:47.59565\tvalid-mae:47.86759\n",
      "[800]\ttrain-mae:45.99632\tvalid-mae:46.39157\n",
      "[1000]\ttrain-mae:44.73640\tvalid-mae:45.25612\n",
      "[1200]\ttrain-mae:43.85012\tvalid-mae:44.48767\n",
      "[1400]\ttrain-mae:43.17632\tvalid-mae:43.93320\n",
      "[1600]\ttrain-mae:42.59860\tvalid-mae:43.47950\n",
      "[1800]\ttrain-mae:42.14130\tvalid-mae:43.13943\n",
      "[2000]\ttrain-mae:41.72985\tvalid-mae:42.84871\n",
      "[2200]\ttrain-mae:41.32850\tvalid-mae:42.56158\n",
      "[2400]\ttrain-mae:40.98554\tvalid-mae:42.33454\n",
      "[2600]\ttrain-mae:40.69290\tvalid-mae:42.15541\n",
      "[2800]\ttrain-mae:40.40587\tvalid-mae:41.97984\n",
      "[2999]\ttrain-mae:40.11851\tvalid-mae:41.80572\n",
      "âœ… Best iter=3000  |  VALID MAE=41.8057\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7: Train with early stopping + VALID MAE ===\n",
    "dtr = xgb.DMatrix(X_tr, label=y_tr, feature_names=FINAL_FEATS)\n",
    "dva = xgb.DMatrix(X_va, label=y_va, feature_names=FINAL_FEATS)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"learning_rate\": 0.06,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_weight\": 4,\n",
    "    \"subsample\": 0.75,\n",
    "    \"colsample_bytree\": 0.85,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"reg_lambda\": 0.6,\n",
    "    \"random_state\": RANDOM_SEED,\n",
    "    # í•„ìš”ì‹œ \"tree_method\": \"gpu_hist\"\n",
    "}\n",
    "\n",
    "print(\"ğŸš€ Training...\")\n",
    "bst = xgb.train(params, dtr, num_boost_round=3000,\n",
    "                evals=[(dtr,\"train\"), (dva,\"valid\")],\n",
    "                early_stopping_rounds=200, verbose_eval=200)\n",
    "\n",
    "best_n = bst.best_iteration + 1\n",
    "pred_va = bst.predict(dva, iteration_range=(0, bst.best_iteration+1)).astype(\"float32\")\n",
    "val_mae = mean_absolute_error(y_va, pred_va)\n",
    "print(f\"âœ… Best iter={best_n}  |  VALID MAE={val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38a6da4-cb33-456f-bb3e-b5cfde4b14ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Full-data training with num_boost_round=3600 ...\n",
      "ğŸ’¾ Saved â†’ xgb_full_final.json\n"
     ]
    }
   ],
   "source": [
    "# === Cell F1: Full-data train (use best_n*1.2) ===\n",
    "# train_raw, FINAL_FEATS, interpolate_weather, params ê°€ ì• ì…€ì—ì„œ ì´ë¯¸ ì •ì˜ë¨\n",
    "\n",
    "train_full = interpolate_weather(train_raw, max_gap=MAX_GAP)\n",
    "use_cols = [c for c in (FINAL_FEATS + [TARGET]) if c in train_full.columns]\n",
    "train_full = train_full[use_cols].copy()\n",
    "train_full[FINAL_FEATS] = train_full[FINAL_FEATS].astype(\"float32\").fillna(0)\n",
    "\n",
    "dfull = xgb.DMatrix(train_full[FINAL_FEATS], label=train_full[TARGET].values, feature_names=FINAL_FEATS)\n",
    "\n",
    "num_round = 3600  # best_n(=3000) * 1.2\n",
    "print(f\"ğŸš€ Full-data training with num_boost_round={num_round} ...\")\n",
    "final_bst = xgb.train(params, dfull, num_boost_round=num_round, verbose_eval=300)\n",
    "final_bst.save_model(\"xgb_full_final.json\")\n",
    "print(\"ğŸ’¾ Saved â†’ xgb_full_final.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff7b420-9aeb-477f-9e8a-5320696de7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_27572\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: result_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell F2: Predict test + save submission ===\n",
    "TEST_CSV = \"test.csv\"\n",
    "SUB_CSV  = \"submission_sample.csv\" if os.path.exists(\"submission_sample.csv\") else \"sample_submission.csv\"\n",
    "\n",
    "test_raw = pd.read_csv(TEST_CSV, low_memory=True, memory_map=True)\n",
    "test_raw = add_features(test_raw)\n",
    "test_itp = interpolate_weather(test_raw, max_gap=MAX_GAP)\n",
    "\n",
    "# ì…ë ¥ ì •ë¦¬\n",
    "feat_exist = [c for c in FINAL_FEATS if c in test_itp.columns]\n",
    "test_mat = test_itp[feat_exist].astype(\"float32\").fillna(0)\n",
    "dte = xgb.DMatrix(test_mat, feature_names=feat_exist)\n",
    "\n",
    "# ì˜ˆì¸¡ + í´ë¦¬í•‘\n",
    "pred = final_bst.predict(dte).astype(\"float32\")\n",
    "pred = np.clip(pred, 0, None)\n",
    "\n",
    "# (ì„ íƒ) ì•¼ê°„ ë³´ìˆ˜ì  í´ë¨í”„: uv_idx<=0 ë˜ëŠ” ì‹œê°„ not in [6,18] â†’ 0\n",
    "if \"uv_idx\" in test_itp.columns and \"hour\" in test_raw.columns:\n",
    "    mask_night = (pd.to_numeric(test_itp[\"uv_idx\"], errors=\"coerce\") <= 0) | ~test_raw[\"hour\"].between(6,18)\n",
    "    pred[mask_night.values] = 0.0\n",
    "\n",
    "# ì œì¶œ í¬ë§· ë§ì¶”ê¸°\n",
    "sub = pd.read_csv(SUB_CSV)\n",
    "if len(sub) == len(pred):\n",
    "    sub[\"nins\"] = pred\n",
    "else:\n",
    "    merge_keys = [k for k in [\"time\",\"pv_id\",\"type\"] if k in sub.columns and k in test_raw.columns]\n",
    "    for df_ in (sub, test_raw):\n",
    "        if \"time\" in df_.columns:\n",
    "            df_[\"time\"] = pd.to_datetime(df_[\"time\"], errors=\"coerce\")\n",
    "    ref = test_raw[merge_keys].copy()\n",
    "    ref[\"nins\"] = pred\n",
    "    sub = sub.drop(columns=[\"nins\"], errors=\"ignore\").merge(ref, on=merge_keys, how=\"left\")\n",
    "\n",
    "sub[\"nins\"] = sub[\"nins\"].fillna(0).astype(\"float32\")\n",
    "sub.to_csv(\"result_submission.csv\", index=False)\n",
    "print(\"âœ… Saved: result_submission.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bca13c-fe67-4e4f-aae1-5b916c6270f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
