{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08caa08-3b42-4aa2-a670-c7057eb52169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup done.\n"
     ]
    }
   ],
   "source": [
    "#셀 1) 기본 세팅 & 임포트\n",
    "# === Speed/Memory oriented setup ===\n",
    "import os, gc, math, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 핵심 모델/평가\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 재현성\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# 경로: 필요시 수정\n",
    "DATA_DIR = \"./\"  # train.csv, test.csv, sample_submission.csv 있는 폴더\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "SUB_CSV   = os.path.join(DATA_DIR, \"submission_sample.csv\")\n",
    "\n",
    "TIME_COL = \"time\"\n",
    "PV_COL   = \"pv_id\"\n",
    "TARGET   = \"nins\"\n",
    "\n",
    "# downcast 유틸\n",
    "def downcast_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for c in df.select_dtypes(include=[\"float64\"]).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"float\")\n",
    "    for c in df.select_dtypes(include=[\"int64\"]).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"integer\")\n",
    "    return df\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "print(\"Setup done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85086a06-24d1-4285-bd49-4b0f783e7879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19236948, 16) (2838240, 16) pv_id dtype: category\n"
     ]
    }
   ],
   "source": [
    "#셀 2) 데이터 로드 (얇게 읽기 + 다운캐스트)\n",
    "# === (패치) 데이터 로드: pv_id는 문자열 → category로 ===\n",
    "CAND_COLS = [\n",
    "    TIME_COL, PV_COL, TARGET,\n",
    "    \"temp_a\",\"temp_max\",\"temp_min\",\"humidity\",\"cloud\",\"rain\",\n",
    "    \"wind_spd_a\",\"wind_spd_b\",\"wind_gust_spd\",\"ground_press\",\n",
    "    \"wind_dir_a\",\"wind_dir_b\",\n",
    "    \"coord1\",\"coord2\"\n",
    "]\n",
    "\n",
    "def read_csv_smart(path, with_target):\n",
    "    head = pd.read_csv(path, nrows=10)\n",
    "    cols = [c for c in CAND_COLS if c in head.columns]\n",
    "\n",
    "    # pv_id는 문자열로 읽고, 나중에 category로 변환\n",
    "    dtype_map = {}\n",
    "    if PV_COL in cols:\n",
    "        dtype_map[PV_COL] = \"string\"   # <-- 여기!\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        usecols=cols,\n",
    "        parse_dates=[TIME_COL] if TIME_COL in cols else None,\n",
    "        dtype=dtype_map if dtype_map else None,\n",
    "        low_memory=True,\n",
    "        memory_map=True\n",
    "    )\n",
    "\n",
    "    # 문자열 정리\n",
    "    if PV_COL in df.columns:\n",
    "        df[PV_COL] = df[PV_COL].astype(\"string\").str.strip()\n",
    "        # 메모리 절약을 위해 카테고리화 (계산시에는 문자열처럼 동작)\n",
    "        df[PV_COL] = df[PV_COL].astype(\"category\")\n",
    "\n",
    "    # 수치 다운캐스트\n",
    "    df = downcast_df(df)\n",
    "\n",
    "    if with_target and TARGET in df.columns:\n",
    "        df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    return df\n",
    "\n",
    "train = read_csv_smart(TRAIN_CSV, with_target=True)\n",
    "test  = read_csv_smart(TEST_CSV,  with_target=False)\n",
    "sub   = pd.read_csv(SUB_CSV)\n",
    "\n",
    "print(train.shape, test.shape, \"pv_id dtype:\", train[PV_COL].dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204e2f16-716e-40bb-9268-c6065500e878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dropna: 19236948 -> 19236948\n"
     ]
    }
   ],
   "source": [
    "#셀 3) 정렬 & 기본 전처리(짧은 결측 보간) + 결측행 제거\n",
    "# 시간 정렬 (안전)\n",
    "train = train.sort_values([PV_COL, TIME_COL]).reset_index(drop=True)\n",
    "test  = test.sort_values([PV_COL, TIME_COL]).reset_index(drop=True)\n",
    "\n",
    "# --- 결측 처리 전략 ---\n",
    "# 1) 같은 pv_id 내부에서 짧은 구간만 interpolate (limit=6) 하고,\n",
    "# 2) train은 잔여 결측행 제거, test는 남으면 bfill/ffill로 마지막 방어\n",
    "num_cols = [c for c in train.columns if c not in [TIME_COL, PV_COL] and pd.api.types.is_numeric_dtype(train[c])]\n",
    "num_cols_test = [c for c in test.columns  if c not in [TIME_COL, PV_COL] and pd.api.types.is_numeric_dtype(test[c])]\n",
    "\n",
    "def short_interp_group(df, cols, group=PV_COL, limit=6):\n",
    "    # 그룹 내 ffill/bfill + 선형보간(짧은 구간만)\n",
    "    df = df.copy()\n",
    "    g = df.groupby(group, group_keys=False)\n",
    "    for c in cols:\n",
    "        if c not in df.columns: \n",
    "            continue\n",
    "        s = g[c].apply(lambda x: x.ffill().bfill().interpolate(limit=limit, limit_direction=\"both\"))\n",
    "        df[c] = s.astype(df[c].dtype)\n",
    "    return df\n",
    "\n",
    "train = short_interp_group(train, [c for c in num_cols if c != TARGET], PV_COL, limit=6)\n",
    "test  = short_interp_group(test,  num_cols_test, PV_COL, limit=6)\n",
    "\n",
    "# train은 남은 결측 제거 (룰 준수)\n",
    "before = len(train)\n",
    "train = train.dropna(subset=[c for c in num_cols if c != TARGET]).reset_index(drop=True)\n",
    "print(f\"train dropna: {before} -> {len(train)}\")\n",
    "\n",
    "# test는 최종 안전장치\n",
    "test = test.fillna(method=\"bfill\").fillna(method=\"ffill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36f97cb-d3c7-4090-a692-0a6ab08957bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#셀 4) 태양고도 기반 cosZ 생성 (+ 야간 마스크)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 한국 중앙값 근사 (coord1/2 없을 때 사용)\n",
    "DEFAULT_LAT = 36.5\n",
    "DEFAULT_LON = 127.9\n",
    "KST_TZNAME  = \"Asia/Seoul\"  # 참고용\n",
    "\n",
    "def solar_cos_zenith(ts: pd.Series, lat=DEFAULT_LAT, lon=DEFAULT_LON, tz_offset_hours=9):\n",
    "    \"\"\"\n",
    "    간단 NOAA 근사.\n",
    "    - 입력 ts가 tz-aware면 Asia/Seoul로 변환 후 tz 제거\n",
    "    - tz-naive면 그대로 사용(로컬 표준시 가정)  → 추가적인 -9시간 보정은 하지 않음\n",
    "    \"\"\"\n",
    "    s = pd.to_datetime(ts, errors=\"coerce\")\n",
    "\n",
    "    # tz 처리: tz-aware면 KST로 변환 후 naive로\n",
    "    try:\n",
    "        if getattr(s.dt, \"tz\", None) is not None:\n",
    "            s = s.dt.tz_convert(KST_TZNAME).dt.tz_localize(None)\n",
    "        else:\n",
    "            # tz-naive → 그대로 사용(로컬 표준시 가정)\n",
    "            s = s.dt.tz_localize(None)\n",
    "    except Exception:\n",
    "        # 어떤 경우에도 datetime64[ns] naive 보장\n",
    "        s = pd.to_datetime(s).dt.tz_localize(None)\n",
    "\n",
    "    # ----- 천문 각도 계산 -----\n",
    "    doy  = s.dt.dayofyear.values.astype(\"int32\")\n",
    "    hour = s.dt.hour.values + s.dt.minute.values/60.0 + s.dt.second.values/3600.0\n",
    "    # Local Standard Time (LST) 계산용 보정항\n",
    "    B   = 2*np.pi*(doy - 81)/364.0\n",
    "    EoT = 9.87*np.sin(2*B) - 7.53*np.cos(B) - 1.5*np.sin(B)  # 분(min)\n",
    "    LSTM = 15 * tz_offset_hours  # 경도 기준(한국=135° 기준이 아님에 주의, 근사식)\n",
    "    TC   = 4*(lon - LSTM) + EoT  # 분(min)\n",
    "\n",
    "    LST  = hour + TC/60.0        # 시간 단위\n",
    "    HRA  = np.deg2rad(15*(LST - 12))  # Hour Angle\n",
    "\n",
    "    delta = np.deg2rad(23.45) * np.sin(2*np.pi*(284 + doy)/365.0)  # 태양 적위\n",
    "    latr  = np.deg2rad(lat)\n",
    "\n",
    "    cosZ = (np.sin(latr)*np.sin(delta) + np.cos(latr)*np.cos(delta)*np.cos(HRA))\n",
    "    return np.clip(cosZ, 0, 1).astype(\"float32\")\n",
    "\n",
    "def attach_cosZ(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    lat = float(pd.to_numeric(df[\"coord1\"], errors=\"coerce\").median()) if \"coord1\" in df.columns else DEFAULT_LAT\n",
    "    lon = float(pd.to_numeric(df[\"coord2\"], errors=\"coerce\").median()) if \"coord2\" in df.columns else DEFAULT_LON\n",
    "    out = df.copy()\n",
    "    out[\"cosZ\"] = solar_cos_zenith(out[TIME_COL], lat=lat, lon=lon, tz_offset_hours=9)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2ffcbf7-06eb-49ca-a641-c091995f8932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cosZ zero ratio: 0.5000193377868465   min/max: 0.0 0.9999527335166931\n",
      "test  cosZ zero ratio: 0.49997146118721464   min/max: 0.0 0.9999555945396423\n",
      "                       time      cosZ\n",
      "0 2024-08-01 00:05:00+09:00  0.678613\n",
      "1 2024-08-01 00:10:00+09:00  0.663813\n",
      "2 2024-08-01 00:15:00+09:00  0.648699\n",
      "3 2024-08-01 00:20:00+09:00  0.633277\n",
      "4 2024-08-01 00:25:00+09:00  0.617554\n"
     ]
    }
   ],
   "source": [
    "print(\"train cosZ zero ratio:\", (train[\"cosZ\"]==0).mean(), \"  min/max:\", float(train[\"cosZ\"].min()), float(train[\"cosZ\"].max()))\n",
    "print(\"test  cosZ zero ratio:\", (test[\"cosZ\"]==0).mean(),  \"  min/max:\", float(test[\"cosZ\"].min()),  float(test[\"cosZ\"].max()))\n",
    "print(train[[TIME_COL,\"cosZ\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4518172-3c67-46a0-ae1e-307e9e3160cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#셀 5) 시간/주기 + 풍향 sin/cos + lag/rolling (필수 최소셋)\n",
    "def add_time_features(df):\n",
    "    df = df.copy()\n",
    "    tt = df[TIME_COL]\n",
    "    df[\"hour\"] = tt.dt.hour.astype(\"int16\")\n",
    "    df[\"dow\"]  = tt.dt.dayofweek.astype(\"int16\")\n",
    "    df[\"doy\"]  = tt.dt.dayofyear.astype(\"int16\")\n",
    "    df[\"is_weekend\"] = (df[\"dow\"]>=5).astype(\"int8\")\n",
    "\n",
    "    # 사이클릭(1차만, 과잉 방지)\n",
    "    df[\"hr_sin1\"] = np.sin(2*np.pi*df[\"hour\"]/24).astype(\"float32\")\n",
    "    df[\"hr_cos1\"] = np.cos(2*np.pi*df[\"hour\"]/24).astype(\"float32\")\n",
    "    df[\"doy_sin1\"]= np.sin(2*np.pi*df[\"doy\"]/365).astype(\"float32\")\n",
    "    df[\"doy_cos1\"]= np.cos(2*np.pi*df[\"doy\"]/365).astype(\"float32\")\n",
    "    return df\n",
    "\n",
    "def add_wind_dir(df):\n",
    "    df = df.copy()\n",
    "    for dcol in [\"wind_dir_a\",\"wind_dir_b\"]:\n",
    "        if dcol in df.columns:\n",
    "            rad = np.deg2rad(pd.to_numeric(df[dcol], errors=\"coerce\"))\n",
    "            df[dcol+\"_sin\"] = np.sin(rad).astype(\"float32\")\n",
    "            df[dcol+\"_cos\"] = np.cos(rad).astype(\"float32\")\n",
    "    return df\n",
    "\n",
    "def add_group_lag_roll(df, cols, group=PV_COL):\n",
    "    df = df.copy()\n",
    "    g = df.groupby(group, sort=False)\n",
    "    for c in cols:\n",
    "        if c not in df.columns: \n",
    "            continue\n",
    "        # lag (1,2), diff(1)\n",
    "        df[f\"{c}_lag1\"] = g[c].shift(1)\n",
    "        df[f\"{c}_lag2\"] = g[c].shift(2)\n",
    "        df[f\"{c}_d1\"]   = g[c].diff(1)\n",
    "        # 30분/60분 rolling: 5분 간격 가정 → 6,12\n",
    "        df[f\"{c}_r30\"]  = g[c].rolling(6, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        df[f\"{c}_r60\"]  = g[c].rolling(12, min_periods=1).median().reset_index(level=0, drop=True)\n",
    "    # 다운캐스트\n",
    "    return downcast_df(df)\n",
    "\n",
    "# 적용 대상(핵심만)\n",
    "BASE_NUMS = [c for c in [\"temp_a\",\"humidity\",\"cloud\",\"rain\",\"wind_spd_a\",\"wind_gust_spd\",\"ground_press\",\"cosZ\"] if c in train.columns]\n",
    "\n",
    "train = add_time_features(train)\n",
    "test  = add_time_features(test)\n",
    "\n",
    "train = add_wind_dir(train)\n",
    "test  = add_wind_dir(test)\n",
    "\n",
    "train = add_group_lag_roll(train, BASE_NUMS, PV_COL)\n",
    "test  = add_group_lag_roll(test,  BASE_NUMS, PV_COL)\n",
    "\n",
    "# 생성 후 생긴 결측(lag 등)은 train에서 제거, test는 ffill/bfill\n",
    "before = len(train)\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "test  = test.fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "\n",
    "print(f\"post feature-engineering train dropna: {before} -> {len(train)}\")\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec88677-9149-40cd-9c1d-cda12700941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = attach_cosZ(train)\n",
    "test  = attach_cosZ(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ee49da-06b2-470e-8832-61809caa3c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 14 cosZ in: True\n"
     ]
    }
   ],
   "source": [
    "#셀 6) 특징 목록 구성 + 단조 제약 준비\n",
    "# 학습에 쓸 최종 FEATURES\n",
    "exclude = {TIME_COL, PV_COL, TARGET}\n",
    "FEATURES = [c for c in train.columns if c not in exclude and pd.api.types.is_numeric_dtype(train[c])]\n",
    "\n",
    "# monotone constraints: cosZ만 +1, 나머지 0\n",
    "mono = [1 if f==\"cosZ\" else 0 for f in FEATURES]\n",
    "print(\"n_features:\", len(FEATURES), \"cosZ in:\", (\"cosZ\" in FEATURES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949266cd-b638-4078-97b1-c83803a293d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable folds: 4\n"
     ]
    }
   ],
   "source": [
    "#셀 7) 라벨 변환 (sqrt) + 시간 기반 Folds (Purged Forward)\n",
    "# sqrt 변환\n",
    "train_y = np.sqrt(train[TARGET].values.astype(\"float32\"))\n",
    "train_X = train[FEATURES].astype(\"float32\")\n",
    "test_X  = test[FEATURES].astype(\"float32\")\n",
    "\n",
    "# Purged forward CV by day: fold i를 검증으로, 이전 모든 날을 학습\n",
    "days = train[TIME_COL].dt.floor(\"D\")\n",
    "uniq_days = np.sort(days.unique())\n",
    "N_SPLITS = 5\n",
    "fold_sizes = np.array_split(uniq_days, N_SPLITS)\n",
    "\n",
    "folds = []\n",
    "used_train_days = set()\n",
    "for i in range(N_SPLITS):\n",
    "    va_days = set(fold_sizes[i])\n",
    "    tr_days = set(uniq_days[:np.where(uniq_days==fold_sizes[i][0])[0][0]])  # i 블록 시작 이전의 모든 날\n",
    "    if len(tr_days)==0:\n",
    "        # 첫 블록은 과거가 없으니 스킵 (유효하지 않은 검증)\n",
    "        continue\n",
    "    va_idx = train.index[days.isin(va_days)].values\n",
    "    tr_idx = train.index[days.isin(tr_days)].values\n",
    "    if len(va_idx)==0 or len(tr_idx)==0: \n",
    "        continue\n",
    "    folds.append((tr_idx, va_idx))\n",
    "\n",
    "print(\"usable folds:\", len(folds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eceabad8-2c37-4c55-81ac-1837fb14b24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's l1: 5.08152\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid's l1: 5.07081\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's l1: 4.27749\n",
      "[400]\tvalid's l1: 4.27345\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid's l1: 4.25944\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\tvalid's l1: 5.15098\n",
      "[400]\tvalid's l1: 5.13524\n",
      "[600]\tvalid's l1: 5.1401\n",
      "Early stopping, best iteration is:\n",
      "[505]\tvalid's l1: 5.13045\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m lgb_tr = lgb.Dataset(Xtr, label=ytr, free_raw_data=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     33\u001b[39m lgb_va = lgb.Dataset(Xva, label=yva, reference=lgb_tr, free_raw_data=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m model = \u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlgb_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb_va\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m models.append(model)\n\u001b[32m     48\u001b[39m oof[va_idx] = model.predict(Xva, num_iteration=model.best_iteration)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\lightgbm\\engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\lightgbm\\basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#셀 8) LightGBM 학습 (규제+EarlyStop+단조제약) + OOF/테스트 예측\n",
    "# 셀 8) LightGBM 학습 (MAE, 단조제약 제거)\n",
    "params = dict(\n",
    "    objective=\"mae\",          # regression_l1\n",
    "    metric=\"mae\",\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=200,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    lambda_l1=2.0,\n",
    "    lambda_l2=2.0,\n",
    "    random_state=SEED,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1\n",
    "    # monotone_constraints 제거!\n",
    ")\n",
    "\n",
    "oof = np.zeros(len(train), dtype=\"float32\")\n",
    "pred_te_accum = np.zeros(len(test), dtype=\"float32\")\n",
    "models = []\n",
    "\n",
    "for fi, (tr_idx, va_idx) in enumerate(folds, 1):\n",
    "    if len(tr_idx) == 0 or len(va_idx) == 0:\n",
    "        print(f\"[fold {fi}] skip: empty index\")\n",
    "        continue\n",
    "\n",
    "    Xtr, ytr = train_X.iloc[tr_idx], train_y[tr_idx]\n",
    "    Xva, yva = train_X.iloc[va_idx], train_y[va_idx]\n",
    "\n",
    "    lgb_tr = lgb.Dataset(Xtr, label=ytr, free_raw_data=True)\n",
    "    lgb_va = lgb.Dataset(Xva, label=yva, reference=lgb_tr, free_raw_data=True)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=lgb_tr,\n",
    "        num_boost_round=5000,\n",
    "        valid_sets=[lgb_va],\n",
    "        valid_names=[\"valid\"],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=200, verbose=True),\n",
    "            lgb.log_evaluation(period=200)\n",
    "        ]\n",
    "    )\n",
    "    models.append(model)\n",
    "\n",
    "    oof[va_idx] = model.predict(Xva, num_iteration=model.best_iteration)\n",
    "    pred_te_accum += model.predict(test_X, num_iteration=model.best_iteration).astype(\"float32\")\n",
    "\n",
    "# --- 역변환 유틸 ---\n",
    "def inv_sqrt(yhat):\n",
    "    # sqrt-space 예측을 원래 스케일로 복원: 음수는 0으로 클립 후 제곱\n",
    "    return np.square(np.clip(yhat, 0, None), dtype=\"float32\")\n",
    "\n",
    "# OOF MAE (역변환)\n",
    "oof_pred = inv_sqrt(oof)\n",
    "oof_mae = mean_absolute_error(train[TARGET].values, oof_pred)\n",
    "print(f\"OOF MAE: {oof_mae:.5f}\")\n",
    "\n",
    "# 테스트 예측 (역변환)\n",
    "pred_te = inv_sqrt(pred_te_accum / max(1, len(models)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ab75a8-c2ef-4b7a-8e28-603886f4f813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocess done.\n"
     ]
    }
   ],
   "source": [
    "#셀 9) 야간 0 고정 + 일출/일몰 스무딩 + 음수 0 클리핑\n",
    "# 야간 = 0\n",
    "cosZ_te = test[\"cosZ\"].values.astype(\"float32\")\n",
    "pred_te[cosZ_te==0] = 0.0\n",
    "\n",
    "# 일출/일몰 스무딩 (완만하게)\n",
    "# cosZ < τ이면 pred *= (cosZ/τ)\n",
    "tau = 0.05\n",
    "mask = (cosZ_te > 0) & (cosZ_te < tau)\n",
    "pred_te[mask] = pred_te[mask] * (cosZ_te[mask] / tau)\n",
    "\n",
    "# 음수 방지\n",
    "pred_te = np.clip(pred_te, 0, None)\n",
    "\n",
    "print(\"postprocess done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c6fe1-b3b4-426a-9f8f-99ee2c616afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빠른 sanity check\n",
    "print(\"OOF MAE (reported above) 확인:\", \"OK\" if np.isfinite(oof_mae) else \"NaN!\")\n",
    "print(\"test pred basic stats:\", float(pred_te.min()), float(pred_te.max()), float(np.median(pred_te)))\n",
    "print(\"postprocess cosZ<0.05 count:\", int((test[\"cosZ\"]<0.05).sum()))\n",
    "print(\"예측 0인 개수:\", int((pred_te==0).sum()), \"/\", len(pred_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae148b90-785c-4885-92a4-d901e619ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration applied.\n"
     ]
    }
   ],
   "source": [
    "#셀 10) 플랜트별 1차 캘리브레이션 (선택) — OOF로 a,b 보정\n",
    "# === (패치) 캘리브레이션: 키를 문자열로 통일 ===\n",
    "\"\"\"\n",
    "calib = {}\n",
    "df_oof = pd.DataFrame({\n",
    "    \"pv_id\": train[PV_COL].astype(\"string\").values,            # <-- 문자열화\n",
    "    \"y\": train[TARGET].values.astype(\"float32\"),\n",
    "    \"yhat\": oof_pred.astype(\"float32\")\n",
    "})\n",
    "\n",
    "# 전역 a,b\n",
    "A_global, B_global = 1.0, 0.0\n",
    "try:\n",
    "    A_global = np.cov(df_oof[\"yhat\"], df_oof[\"y\"])[0,1] / (np.var(df_oof[\"yhat\"]) + 1e-6)\n",
    "    B_global = df_oof[\"y\"].mean() - A_global * df_oof[\"yhat\"].mean()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "for pid, g in df_oof.groupby(\"pv_id\"):\n",
    "    if len(g) < 200:\n",
    "        calib[str(pid)] = (A_global, B_global)                 # <-- str(pid)\n",
    "    else:\n",
    "        try:\n",
    "            A = np.cov(g[\"yhat\"], g[\"y\"])[0,1] / (np.var(g[\"yhat\"]) + 1e-6)\n",
    "            B = g[\"y\"].mean() - A * g[\"yhat\"].mean()\n",
    "            calib[str(pid)] = (float(A), float(B))             # <-- str(pid)\n",
    "        except Exception:\n",
    "            calib[str(pid)] = (A_global, B_global)\n",
    "\n",
    "pid_arr = test[PV_COL].astype(\"string\").values                 # <-- 문자열화\n",
    "A_vec = np.array([calib.get(p, (A_global, B_global))[0] for p in pid_arr], dtype=\"float32\")\n",
    "B_vec = np.array([calib.get(p, (A_global, B_global))[1] for p in pid_arr], dtype=\"float32\")\n",
    "\n",
    "pred_te_cal = A_vec * pred_te + B_vec\n",
    "pred_te_cal = np.clip(pred_te_cal, 0, None).astype(\"float32\")\n",
    "print(\"Calibration applied.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7559c7-e63c-4266-aae5-e2d706fc1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 10) (임시) 캘리브레이션 OFF → 그대로 통과\n",
    "pred_te_cal = pred_te.copy()\n",
    "print(\"Calibration skipped (temporary).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8afffd-b9ce-4ead-97cb-845d0e0f6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 10) (임시) 캘리브레이션 OFF → 그대로 통과\n",
    "pred_te_cal = pred_te.copy()\n",
    "print(\"Calibration skipped (temporary).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ebc05c0-2374-466a-bf65-cf888e366123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./result_submission.csv\n",
      "dtypes: {'time': dtype('<M8[ns]'), 'pv_id': string[python], 'type': string[python], 'nins': dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "#셀 11) 제출파일 생성 (키 머지 안전)\n",
    "# 셀 11) 제출파일 생성 (키 정규화 + 안전 병합)  [patched]\n",
    "\n",
    "def norm_time(s):\n",
    "    # 모두 naive datetime64[ns]로 통일\n",
    "    s = pd.to_datetime(s, errors=\"coerce\")\n",
    "    try:\n",
    "        # tz-aware면 KST로 변환 후 tz 제거\n",
    "        if getattr(s.dt, \"tz\", None) is not None:\n",
    "            s = s.dt.tz_convert(\"Asia/Seoul\").dt.tz_localize(None)\n",
    "        else:\n",
    "            s = s.dt.tz_localize(None)  # naive인 경우에도 형식 통일\n",
    "    except Exception:\n",
    "        s = pd.to_datetime(s, errors=\"coerce\")\n",
    "    return s\n",
    "\n",
    "def norm_keys(df):\n",
    "    out = df.copy()\n",
    "    if \"time\" in out.columns:\n",
    "        out[\"time\"] = norm_time(out[\"time\"])\n",
    "    if \"pv_id\" in out.columns:\n",
    "        out[\"pv_id\"] = out[\"pv_id\"].astype(\"string\").str.strip()\n",
    "    if \"type\" in out.columns:\n",
    "        out[\"type\"] = out[\"type\"].astype(\"string\").str.strip()\n",
    "    return out\n",
    "\n",
    "# 1) 키 정규화\n",
    "sub_norm  = norm_keys(sub)\n",
    "test_norm = norm_keys(test)\n",
    "\n",
    "# 2) 참조 테이블 만들기\n",
    "merge_keys = [c for c in [\"time\",\"pv_id\",\"type\"] if c in sub_norm.columns]\n",
    "ref = test_norm[[TIME_COL, PV_COL]].copy()\n",
    "\n",
    "if \"type\" in sub_norm.columns and \"type\" not in ref.columns:\n",
    "    # (time, pv_id) 조합을 sample의 type과 매칭\n",
    "    ref = ref.merge(\n",
    "        sub_norm[merge_keys].drop_duplicates(),\n",
    "        on=[\"time\",\"pv_id\"], how=\"left\"\n",
    "    )\n",
    "\n",
    "# 3) 예측치 붙이기\n",
    "ref[\"nins\"] = pred_te_cal.astype(\"float32\")\n",
    "\n",
    "# 4) 안전 병합 (중복 컬럼 제거)\n",
    "def safe_merge(left: pd.DataFrame, right: pd.DataFrame, on, how=\"left\") -> pd.DataFrame:\n",
    "    right = right.loc[:, ~right.columns.duplicated()]\n",
    "    return left.merge(right, on=on, how=how, copy=False)\n",
    "\n",
    "out = safe_merge(\n",
    "    sub_norm.drop(columns=[\"nins\"]) if \"nins\" in sub_norm.columns else sub_norm,\n",
    "    ref,\n",
    "    on=merge_keys, how=\"left\"\n",
    ")\n",
    "\n",
    "SAVE_PATH = os.path.join(DATA_DIR, \"result_submission.csv\")\n",
    "out.to_csv(SAVE_PATH, index=False)\n",
    "print(\"Saved:\", SAVE_PATH)\n",
    "print(\"dtypes:\", out.dtypes.loc[[\"time\",\"pv_id\",\"type\",\"nins\"]].to_dict() if set([\"time\",\"pv_id\",\"type\"]).issubset(out.columns) else out.dtypes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e1eb1-058f-4f42-97c9-857f7e354366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ef69b-4a7c-4e62-a47f-c3e688e193b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e573949-74c2-4133-989b-0f1c6899d9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeafb7be-73a8-40b7-a9a6-60e4b1a49aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF MAE: 133.07325744628906\n",
      "train cosZ zero ratio: 0.5000193377868465 min/max: 0.0 0.9999527335166931\n",
      "test  cosZ zero ratio: 0.49997146118721464 min/max: 0.0 0.9999555945396423\n",
      "pred_te stats: 0.0 741.2813720703125 4.3305945635063736e-11\n",
      "pred_te==0: 1419039 / 2838240\n",
      "sub keys: {'time': dtype('O'), 'pv_id': dtype('O'), 'type': dtype('O')}\n",
      "test keys: {'time': datetime64[ns, UTC+09:00], 'pv_id': CategoricalDtype(categories=['PV_ID_10', 'PV_ID_114', 'PV_ID_117', 'PV_ID_121',\n",
      "                  'PV_ID_122', 'PV_ID_134', 'PV_ID_165', 'PV_ID_173',\n",
      "                  'PV_ID_175', 'PV_ID_180', 'PV_ID_182', 'PV_ID_183',\n",
      "                  'PV_ID_192', 'PV_ID_194', 'PV_ID_204', 'PV_ID_23',\n",
      "                  'PV_ID_29', 'PV_ID_39', 'PV_ID_48', 'PV_ID_49', 'PV_ID_64',\n",
      "                  'PV_ID_7', 'PV_ID_72', 'PV_ID_78', 'PV_ID_8', 'PV_ID_82',\n",
      "                  'PV_ID_95'],\n",
      ", ordered=False, categories_dtype=string)}\n",
      "submission nins null: 0\n",
      "submission duplicate key rows: 0\n"
     ]
    }
   ],
   "source": [
    "# 디버그 셀 A — 기본 분포/정렬/키 점검\n",
    "print(\"OOF MAE:\", oof_mae if 'oof_mae' in globals() else 'N/A')\n",
    "print(\"train cosZ zero ratio:\", (train[\"cosZ\"]==0).mean(), \"min/max:\", float(train[\"cosZ\"].min()), float(train[\"cosZ\"].max()))\n",
    "print(\"test  cosZ zero ratio:\", (test[\"cosZ\"]==0).mean(),  \"min/max:\", float(test[\"cosZ\"].min()),  float(test[\"cosZ\"].max()))\n",
    "\n",
    "print(\"pred_te stats:\", float(pred_te.min()), float(pred_te.max()), float(np.median(pred_te)))\n",
    "print(\"pred_te==0:\", int((pred_te==0).sum()), \"/\", len(pred_te))\n",
    "\n",
    "# 디버그 셀 B — 제출 키 정합성\n",
    "print(\"sub keys:\", sub[['time','pv_id','type']].dtypes.to_dict())\n",
    "print(\"test keys:\", test[['time','pv_id']].dtypes.to_dict())\n",
    "\n",
    "# 제출 병합 후 누락/중복 검사\n",
    "print(\"submission nins null:\", out[\"nins\"].isna().sum())\n",
    "dups = out.duplicated(subset=['time','pv_id','type']).sum()\n",
    "print(\"submission duplicate key rows:\", dups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa0bac-18b1-46d6-bd73-6d0c4d36c8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
