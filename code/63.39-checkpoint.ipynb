{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980ed366-eeda-4b13-8d25-68a0200e1c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup done.\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 0: Setup =====\n",
    "import os, gc, warnings, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "# 경로는 니 노트북 기준으로 맞춰줘\n",
    "DATA_DIR = \"./\"   # train.csv, test.csv, sample_submission.csv 있는 폴더\n",
    "SAVE_SUB = \"./result_submission.csv\"\n",
    "\n",
    "TIME_COL = \"time\"\n",
    "PV_COL   = \"pv_id\"\n",
    "TARGET   = \"nins\"        # 일사량 타깃\n",
    "\n",
    "# 메모리 다운캐스트\n",
    "def downcast_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for c in df.select_dtypes(include=[\"float64\"]).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"float\")\n",
    "    for c in df.select_dtypes(include=[\"int64\"]).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"integer\")\n",
    "    return df\n",
    "\n",
    "# 안전 merge (좌측키 보존, 중복열 접미사 방지)\n",
    "def safe_merge(left: pd.DataFrame, right: pd.DataFrame, on: str, how=\"left\") -> pd.DataFrame:\n",
    "    right = right.loc[:, ~right.columns.duplicated()]\n",
    "    return left.merge(right, on=on, how=how, copy=False)\n",
    "\n",
    "print(\"Setup done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a7c091-69bc-4d20-b91d-e4d5088b145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19236948, 12) (2838240, 11) loaded.\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 1: Load CSVs (thin) =====\n",
    "# 필요한 열만 지정 (파일 열 목록에 맞춰 적당히 수정)\n",
    "base_cols = [TIME_COL, PV_COL, TARGET]\n",
    "# 대표 변수군(예시) — 파일 실제 열 이름에 맞춰 조정해\n",
    "REP_VARS = [\n",
    "    \"temp_a\",\"humidity\",\"cloud\",\"rain\",\"wind_spd_a\",\"wind_spd_b\",\n",
    "    \"wind_gust_spd\",\"ground_press\"\n",
    "]\n",
    "# 풍향 관련(사인/코사인 변환해 쓸 수 있음)\n",
    "WIND_DIR_COLS = [\"wind_dir_a\",\"wind_dir_b\"]\n",
    "\n",
    "AUX_KEEP_RAW = []  # 유지하고 싶은 기타 원본 열 있으면 넣기\n",
    "\n",
    "keep_cols = list(dict.fromkeys(base_cols + REP_VARS + WIND_DIR_COLS + AUX_KEEP_RAW))\n",
    "\n",
    "dtype_hint = {c: \"float32\" for c in keep_cols if c not in [TIME_COL, PV_COL, TARGET]}\n",
    "dtype_hint[TARGET] = \"float32\"\n",
    "\n",
    "def read_csv_thin(path: str, usecols: List[str]) -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        usecols=lambda c: c in usecols,\n",
    "        parse_dates=[TIME_COL],\n",
    "        dtype=dtype_hint,\n",
    "        low_memory=True,\n",
    "        memory_map=True\n",
    "    )\n",
    "\n",
    "train = read_csv_thin(os.path.join(DATA_DIR, \"train.csv\"), keep_cols)\n",
    "test  = read_csv_thin(os.path.join(DATA_DIR, \"test.csv\"),  [c for c in keep_cols if c != TARGET])\n",
    "\n",
    "# pv_id를 카테고리로 (메모리↓)\n",
    "if train[PV_COL].dtype != \"category\":\n",
    "    train[PV_COL] = train[PV_COL].astype(\"category\")\n",
    "if test[PV_COL].dtype != \"category\":\n",
    "    test[PV_COL] = test[PV_COL].astype(\"category\")\n",
    "\n",
    "train = downcast_df(train); test = downcast_df(test)\n",
    "print(train.shape, test.shape, \"loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64701200-edb1-41c1-8565-92451820c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords attached: True\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: Attach coords by pv_id =====\n",
    "# coord_map: [pv_id, coord1(lat), coord2(lon)] 형태의 DataFrame이 있다면 여기로 읽어 붙이기.\n",
    "# 없다면 전국 평균(대략)으로 기본값 부여. (나중에 실제 좌표가 있으면 merge만 바꿔주면 됨)\n",
    "\n",
    "def attach_coords_by_pvid(df: pd.DataFrame, coord_map: pd.DataFrame=None) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    if coord_map is None or not {\"pv_id\",\"coord1\",\"coord2\"}.issubset(set(coord_map.columns)):\n",
    "        # 기본값 (대한민국 중심 근사)\n",
    "        default_lat, default_lon = 36.5, 127.8\n",
    "        # pv_id별 개별 좌표가 없다면, 고유 pv에 동일 기본값 부여\n",
    "        uniq = pd.DataFrame({PV_COL: out[PV_COL].cat.categories})\n",
    "        uniq[\"coord1\"] = default_lat\n",
    "        uniq[\"coord2\"] = default_lon\n",
    "        coord_map = uniq\n",
    "\n",
    "    # 안전 머지\n",
    "    out = safe_merge(out, coord_map.rename(columns={PV_COL:\"pv_id\"}), on=\"pv_id\", how=\"left\")\n",
    "    # 수치화 + 기본값 보정\n",
    "    out[\"coord1\"] = pd.to_numeric(out[\"coord1\"], errors=\"coerce\").fillna(36.5).astype(\"float32\")\n",
    "    out[\"coord2\"] = pd.to_numeric(out[\"coord2\"], errors=\"coerce\").fillna(127.8).astype(\"float32\")\n",
    "    return out\n",
    "\n",
    "# 만약 coord_map.csv가 따로 있으면 아래 주석 해제해서 사용\n",
    "# coord_map = pd.read_csv(os.path.join(DATA_DIR, \"coord_map.csv\"))\n",
    "coord_map = None\n",
    "\n",
    "train = attach_coords_by_pvid(train, coord_map)\n",
    "test  = attach_coords_by_pvid(test,  coord_map)\n",
    "print(\"coords attached:\", set([\"coord1\",\"coord2\"]).issubset(train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa9035d-7ed6-4012-997c-3df1ce998d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pv_id dtype: category | nunique: 183\n",
      "test  pv_id dtype: category | nunique: 27\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2.9: Force categorical for pv_id =====\n",
    "import pandas as pd\n",
    "\n",
    "def ensure_categorical_pvid(df: pd.DataFrame, col: str = PV_COL):\n",
    "    # 문자열로 강제 후 카테고리화 (혼재형/숫자형도 안전)\n",
    "    if df[col].dtype != \"category\":\n",
    "        df[col] = df[col].astype(str).astype(\"category\")\n",
    "    return df\n",
    "\n",
    "train = ensure_categorical_pvid(train, PV_COL)\n",
    "test  = ensure_categorical_pvid(test,  PV_COL)\n",
    "\n",
    "print(\"train pv_id dtype:\", train[PV_COL].dtype, \"| nunique:\", train[PV_COL].nunique())\n",
    "print(\"test  pv_id dtype:\", test[PV_COL].dtype,  \"| nunique:\", test[PV_COL].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede4c872-2ae1-439e-bcd9-b40e5491175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split pv counts: 137 46 27\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 3: Split by pv_id =====\n",
    "# pv_id별 분할: 발전소 편향을 검증에 남겨 일반화 확인\n",
    "pvs = train[PV_COL].cat.categories.tolist()\n",
    "pvs_tr, pvs_va = train_test_split(pvs, test_size=0.25, random_state=SEED, shuffle=True)\n",
    "\n",
    "m_tr = train[PV_COL].isin(pvs_tr)\n",
    "m_va = train[PV_COL].isin(pvs_va)\n",
    "\n",
    "df_tr = train.loc[m_tr].copy()\n",
    "df_va = train.loc[m_va].copy()\n",
    "\n",
    "# 정렬 (롤링 전 필수)\n",
    "df_tr = df_tr.sort_values([PV_COL, TIME_COL])\n",
    "df_va = df_va.sort_values([PV_COL, TIME_COL])\n",
    "test  = test.sort_values([PV_COL, TIME_COL])\n",
    "\n",
    "print(\"Split pv counts:\", df_tr[PV_COL].nunique(), df_va[PV_COL].nunique(), test[PV_COL].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9811e0e-6781-48b0-bdb6-032960a0fac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After bfill + dropna: (14401396, 14) (4835519, 14) (2838240, 13)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 4: Interpolation (pv_id-wise) =====\n",
    "# 규칙: pv_id별로 기상변수 결측치를 bfill. (train은 이후 결측행 drop)\n",
    "fill_cols = [c for c in REP_VARS + WIND_DIR_COLS if c in df_tr.columns]\n",
    "\n",
    "def bfill_by_group(df: pd.DataFrame, cols: List[str], group_col: str) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[cols] = out.groupby(group_col, observed=True)[cols].bfill()\n",
    "    return out\n",
    "\n",
    "df_tr = bfill_by_group(df_tr, fill_cols, PV_COL)\n",
    "df_va = bfill_by_group(df_va, fill_cols, PV_COL)\n",
    "test  = bfill_by_group(test,  fill_cols, PV_COL)\n",
    "\n",
    "# train에서 해당 feature 결측행 제거(룰)\n",
    "df_tr = df_tr.dropna(subset=fill_cols)\n",
    "# valid/test는 남겨두고 이후 모델이 다룸 (또는 2차 보정)\n",
    "print(\"After bfill + dropna:\", df_tr.shape, df_va.shape, test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c461e7a2-5d89-4d0b-86ea-a011431a349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solar geometry added (hotfix): elev_sin, AM, G0h\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 5 (HOTFIX): Solar geometry (precise) =====\n",
    "def ensure_kst_series(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    time Series -> Asia/Seoul 기준의 tz-naive Series로 변환.\n",
    "    tz가 붙어 있으면 KST로 변환 후 tz 제거, 없으면 그대로 KST 가정.\n",
    "    \"\"\"\n",
    "    s = pd.to_datetime(s, errors=\"coerce\")\n",
    "    # tz-aware면 KST로 변환 후 tz 제거\n",
    "    try:\n",
    "        if pd.api.types.is_datetime64tz_dtype(s.dtype):\n",
    "            s = s.dt.tz_convert(\"Asia/Seoul\").dt.tz_localize(None)\n",
    "        else:\n",
    "            # tz-naive면 KST로 가정 (그대로 사용)\n",
    "            pass\n",
    "    except Exception:\n",
    "        # pandas 버전에 따라 is_datetime64tz_dtype 경고/오류 대비\n",
    "        # tz 속성 존재 여부로 분기\n",
    "        if getattr(s.dt, \"tz\", None) is not None:\n",
    "            s = s.dt.tz_convert(\"Asia/Seoul\").dt.tz_localize(None)\n",
    "    return s\n",
    "\n",
    "def solar_geom_inplace(df: pd.DataFrame, lat_col=\"coord1\", lon_col=\"coord2\", time_col=TIME_COL):\n",
    "    # 1) 시간 파트 (Series + .dt 접근자 사용)\n",
    "    t = ensure_kst_series(df[time_col])\n",
    "    doy  = t.dt.dayofyear.astype(\"int16\")\n",
    "    hour = t.dt.hour + t.dt.minute/60.0 + t.dt.second/3600.0  # decimal hour (float)\n",
    "\n",
    "    # 2) 위경도 (rad/deg)\n",
    "    lat = np.deg2rad(df[lat_col].astype(\"float64\").values)\n",
    "    lon = df[lon_col].astype(\"float64\").values\n",
    "\n",
    "    # 3) 태양 적위/시간방정식 (NOAA 근사식)\n",
    "    gamma = 2.0 * np.pi * (doy - 1) / 365.0\n",
    "    decl = (0.006918 \n",
    "            - 0.399912*np.cos(gamma) + 0.070257*np.sin(gamma)\n",
    "            - 0.006758*np.cos(2*gamma) + 0.000907*np.sin(2*gamma)\n",
    "            - 0.002697*np.cos(3*gamma) + 0.00148*np.sin(3*gamma))\n",
    "    eqtime = (229.18*(0.000075 + 0.001868*np.cos(gamma) - 0.032077*np.sin(gamma)\n",
    "                      - 0.014615*np.cos(2*gamma) - 0.040849*np.sin(2*gamma)))  # minutes\n",
    "\n",
    "    # 4) 지역 태양시(Local Solar Time) → 시각각(HRA)\n",
    "    #    한국 표준시는 135E 기준 (UTC+9). 분 단위 보정:\n",
    "    time_offset = eqtime + 4.0*(lon - 135.0)     # minutes\n",
    "    tst = hour*60.0 + time_offset                # true solar time [minutes]\n",
    "    hra = np.deg2rad((tst/4.0) - 180.0)          # hour angle [rad]\n",
    "\n",
    "    # 5) 고도각(sin) 및 클리핑\n",
    "    sin_elev = (np.sin(lat)*np.sin(decl) + np.cos(lat)*np.cos(decl)*np.cos(hra))\n",
    "    sin_elev = np.clip(sin_elev, -1.0, 1.0)\n",
    "    elev_sin = np.maximum(sin_elev, 0.0).astype(\"float32\")  # 지평선 아래 0\n",
    "\n",
    "    # 6) 상대 대기질량 AM (Kasten & Young 1989)\n",
    "    elev = np.rad2deg(np.arcsin(np.clip(sin_elev, 0, 1)))   # deg, 음수구간 0으로 클리핑\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        am = 1.0 / (np.sin(np.deg2rad(np.maximum(elev, 0.0))) + 0.50572 * (6.07995 + elev) ** -1.6364)\n",
    "    am = np.where(elev <= 0, np.nan, am).astype(\"float32\")  # 밤에는 NaN\n",
    "\n",
    "    # 7) 청천 상층대기 수평 일사 G0h\n",
    "    I_sc = 1367.0  # W/m^2\n",
    "    E0 = 1.00011 + 0.034221*np.cos(gamma) + 0.00128*np.sin(gamma) \\\n",
    "                 + 0.000719*np.cos(2*gamma) + 0.000077*np.sin(2*gamma)\n",
    "    G0h = (I_sc * E0 * np.maximum(sin_elev, 0.0)).astype(\"float32\")\n",
    "\n",
    "    df[\"elev_sin\"] = elev_sin\n",
    "    df[\"AM\"]       = am\n",
    "    df[\"G0h\"]      = G0h\n",
    "\n",
    "for _df in (df_tr, df_va, test):\n",
    "    solar_geom_inplace(_df)\n",
    "\n",
    "print(\"Solar geometry added (hotfix): elev_sin, AM, G0h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c54434c-c765-4485-ac99-62b5e201007b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pv_id_code added. unique codes: 137 46 27\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 6 (HOTFIX): Fixed effects (pv_id_code robust) =====\n",
    "def build_pv_codebook(dfs, col=PV_COL):\n",
    "    # 문자열 통일 후 전체 유니온으로 코드북 생성\n",
    "    ser = pd.concat([d[col].astype(str) for d in dfs], ignore_index=True)\n",
    "    uniq = pd.Index(ser.unique())\n",
    "    return {p: i for i, p in enumerate(uniq)}\n",
    "\n",
    "pv2code = build_pv_codebook([df_tr, df_va, test], col=PV_COL)\n",
    "\n",
    "def add_pv_code(df: pd.DataFrame, col=PV_COL):\n",
    "    # 매핑 누락(-1) 방지: fillna(-1) 후 정수 캐스팅\n",
    "    code = df[col].astype(str).map(pv2code)\n",
    "    df[\"pv_id_code\"] = code.fillna(-1).astype(\"int16\")\n",
    "\n",
    "for _df in (df_tr, df_va, test):\n",
    "    add_pv_code(_df)\n",
    "\n",
    "print(\"pv_id_code added. unique codes:\",\n",
    "      df_tr[\"pv_id_code\"].nunique(),\n",
    "      df_va[\"pv_id_code\"].nunique(),\n",
    "      test[\"pv_id_code\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d37c4d-e4cd-449d-a435-3f89f4f1eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling features added.\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 7: Light rolling features =====\n",
    "# 3스텝 롤링: precip_3h_sum, cloud_mean_3 (데이터가 5분 간격이면 15분 윈도우)\n",
    "def add_rolling_inplace(df: pd.DataFrame) -> None:\n",
    "    if \"rain\" in df.columns:\n",
    "        df[\"precip_3h_sum\"] = (\n",
    "            df.groupby(PV_COL, observed=True)[\"rain\"]\n",
    "              .rolling(window=3, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "              .astype(\"float32\")\n",
    "        )\n",
    "    if \"cloud\" in df.columns:\n",
    "        df[\"cloud_mean_3\"] = (\n",
    "            df.groupby(PV_COL, observed=True)[\"cloud\"]\n",
    "              .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "              .astype(\"float32\")\n",
    "        )\n",
    "\n",
    "for _df in (df_tr, df_va, test):\n",
    "    add_rolling_inplace(_df)\n",
    "\n",
    "print(\"Rolling features added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514e0152-31cf-400c-bc7e-fb82d65cc00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time & wind encodings added. (TZ-safe)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 8 (HOTFIX): Lightweight time & wind encodings (TZ-safe) =====\n",
    "def add_time_covariates(df: pd.DataFrame, time_col=TIME_COL):\n",
    "    # Cell 5에 정의한 ensure_kst_series() 재사용: tz-aware → Asia/Seoul → tz 제거\n",
    "    t = ensure_kst_series(df[time_col])\n",
    "    df[\"hour\"] = t.dt.hour.astype(\"int8\")\n",
    "    df[\"doy\"]  = t.dt.dayofyear.astype(\"int16\")\n",
    "    # 주기 인코딩\n",
    "    df[\"hr_sin1\"] = np.sin(2*np.pi*df[\"hour\"]/24).astype(\"float32\")\n",
    "    df[\"hr_cos1\"] = np.cos(2*np.pi*df[\"hour\"]/24).astype(\"float32\")\n",
    "    df[\"dy_sin1\"] = np.sin(2*np.pi*df[\"doy\"]/365).astype(\"float32\")\n",
    "    df[\"dy_cos1\"] = np.cos(2*np.pi*df[\"doy\"]/365).astype(\"float32\")\n",
    "\n",
    "def add_wind_dir_xy(df: pd.DataFrame):\n",
    "    for c in [\"wind_dir_a\",\"wind_dir_b\"]:\n",
    "        if c in df.columns:\n",
    "            r = np.deg2rad(pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\"))\n",
    "            df[f\"{c}_sin\"] = np.sin(r).astype(\"float32\")\n",
    "            df[f\"{c}_cos\"] = np.cos(r).astype(\"float32\")\n",
    "\n",
    "for _df in (df_tr, df_va, test):\n",
    "    add_time_covariates(_df)\n",
    "    add_wind_dir_xy(_df)\n",
    "\n",
    "print(\"Time & wind encodings added. (TZ-safe)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1496b0e7-aa73-43aa-b85e-87881122df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (7217434, 26) (7217434,) (4835519, 26) (4835519,)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 9: Build train/valid matrices (daytime mask) =====\n",
    "# 주간만(물리적 신호 있는 구간)으로 학습\n",
    "mask_day_tr = (df_tr[\"elev_sin\"] > 0)\n",
    "\n",
    "feature_cols = [c for c in df_tr.columns\n",
    "                if c not in [TARGET, TIME_COL, PV_COL] and not c.startswith(\"Unnamed\")]\n",
    "\n",
    "X_tr = df_tr.loc[mask_day_tr, feature_cols]\n",
    "y_tr = df_tr.loc[mask_day_tr, TARGET].astype(\"float32\")\n",
    "\n",
    "X_va = df_va.loc[:, feature_cols]\n",
    "y_va = df_va[TARGET].astype(\"float32\")\n",
    "\n",
    "# 결측 간단 대체(안정성): 수평 일사/고도/구름 등으로 특정 결측이 생길 수 있음\n",
    "X_tr = X_tr.fillna(0); X_va = X_va.fillna(0)\n",
    "\n",
    "print(\"Shapes:\", X_tr.shape, y_tr.shape, X_va.shape, y_va.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17fb23c9-2740-4150-9a8c-830e783a8062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 82.5333\n",
      "[100]\tvalid_0's l1: 67.2547\n",
      "[150]\tvalid_0's l1: 65.3597\n",
      "[200]\tvalid_0's l1: 64.5577\n",
      "[250]\tvalid_0's l1: 64.266\n",
      "[300]\tvalid_0's l1: 63.9363\n",
      "[350]\tvalid_0's l1: 64.0036\n",
      "[400]\tvalid_0's l1: 63.9183\n",
      "[450]\tvalid_0's l1: 63.667\n",
      "[500]\tvalid_0's l1: 63.492\n",
      "[550]\tvalid_0's l1: 63.5613\n",
      "[600]\tvalid_0's l1: 63.1071\n",
      "[650]\tvalid_0's l1: 63.3618\n",
      "[700]\tvalid_0's l1: 63.216\n",
      "[750]\tvalid_0's l1: 63.1841\n",
      "Early stopping, best iteration is:\n",
      "[596]\tvalid_0's l1: 63.0027\n",
      "Baseline valid MAE: 62.9832 | best_iter=596\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 10: First training (HOTFIX) =====\n",
    "params = dict(\n",
    "    objective=\"mae\",\n",
    "    metric=\"mae\",          # metric 명시\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    num_leaves=256,\n",
    "    min_data_in_leaf=80,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1          # 콘솔 로그 억제\n",
    ")\n",
    "\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=200),\n",
    "    lgb.log_evaluation(period=50)  # 50스텝마다 로그; 조용히 하려면 주석\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_va, y_va)],\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# best_iteration_ 가 없을 수 있어 대비\n",
    "best_iter = getattr(model, \"best_iteration_\", None)\n",
    "pred_va = model.predict(X_va, num_iteration=best_iter)\n",
    "pred_va = np.maximum(pred_va, 0.0)\n",
    "mae0 = mean_absolute_error(y_va, pred_va)\n",
    "print(f\"Baseline valid MAE: {mae0:.4f} | best_iter={best_iter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f435c9d8-3c44-4463-9a75-63a60b76397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will drop features (#): 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['coord1', 'coord2', 'pv_id_code'], '')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Cell 11: Permutation importance on valid =====\n",
    "def permutation_importance_mae(\n",
    "    model, X: pd.DataFrame, y: pd.Series, base_mae: float,\n",
    "    n_repeats: int = 1, random_state: int = SEED, sample_frac: float = 0.6\n",
    ") -> pd.DataFrame:\n",
    "    rng = check_random_state(random_state)\n",
    "    # 속도 위해 서브샘플\n",
    "    if sample_frac < 1.0:\n",
    "        idx = rng.choice(X.index.values, size=int(len(X)*sample_frac), replace=False)\n",
    "        Xs, ys = X.loc[idx], y.loc[idx]\n",
    "    else:\n",
    "        Xs, ys = X, y\n",
    "\n",
    "    base_pred = model.predict(Xs, num_iteration=model.best_iteration_)\n",
    "    base_pred = np.maximum(base_pred, 0.0)\n",
    "    base = mean_absolute_error(ys, base_pred)\n",
    "\n",
    "    scores = []\n",
    "    for col in Xs.columns:\n",
    "        worst = []\n",
    "        for _ in range(n_repeats):\n",
    "            Xp = Xs.copy()\n",
    "            Xp[col] = rng.permutation(Xp[col].values)  # 셔플\n",
    "            pred = model.predict(Xp, num_iteration=model.best_iteration_)\n",
    "            pred = np.maximum(pred, 0.0)\n",
    "            m = mean_absolute_error(ys, pred)\n",
    "            worst.append(m)\n",
    "        inc = np.mean(worst) - base\n",
    "        scores.append((col, inc, 100.0 * (inc / (base + 1e-8))))\n",
    "    imp = pd.DataFrame(scores, columns=[\"feature\",\"delta_mae\",\"delta_mae_pct\"]).sort_values(\"delta_mae_pct\", ascending=False)\n",
    "    return imp\n",
    "\n",
    "imp = permutation_importance_mae(model, X_va, y_va, mae0, n_repeats=1, sample_frac=0.6)\n",
    "# 컷 규칙\n",
    "weak_thresh = 0.2  # ΔMAE% ≤ 0.2% 면 약한 피처로 간주\n",
    "weak_feats = imp.loc[imp[\"delta_mae_pct\"] <= weak_thresh, \"feature\"].tolist()\n",
    "\n",
    "# 중복쌍 룰 (데이터에 존재하는 열만 체크)\n",
    "redundant_pairs = [\n",
    "    (\"humidity\", \"rel_hum\"),  # 예시: 실제 파일에 rel_hum이 없으면 무시됨\n",
    "    (\"rain\", \"precip_1h\"),\n",
    "    (\"cloud\", \"cloud_mean_3\"),\n",
    "]\n",
    "to_drop_dup = []\n",
    "for a,b in redundant_pairs:\n",
    "    if a in X_va.columns and b in X_va.columns:\n",
    "        # 더 약한 쪽을 드랍\n",
    "        da = imp.loc[imp[\"feature\"]==a, \"delta_mae_pct\"].values\n",
    "        db = imp.loc[imp[\"feature\"]==b, \"delta_mae_pct\"].values\n",
    "        if len(da)==0 or len(db)==0: \n",
    "            continue\n",
    "        if da[0] >= db[0]:\n",
    "            to_drop_dup.append(b)\n",
    "        else:\n",
    "            to_drop_dup.append(a)\n",
    "\n",
    "drop_feats = sorted(set(weak_feats + to_drop_dup))\n",
    "print(\"Will drop features (#):\", len(drop_feats))\n",
    "drop_feats[:20], (\"...more\" if len(drop_feats)>20 else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97af717-618e-4f4f-8234-cedd5082ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 82.3946\n",
      "[100]\tvalid_0's l1: 64.91\n",
      "[150]\tvalid_0's l1: 62.4495\n",
      "[200]\tvalid_0's l1: 61.5328\n",
      "[250]\tvalid_0's l1: 60.898\n",
      "[300]\tvalid_0's l1: 60.4462\n",
      "[350]\tvalid_0's l1: 59.9578\n",
      "[400]\tvalid_0's l1: 59.7419\n",
      "[450]\tvalid_0's l1: 59.4027\n",
      "[500]\tvalid_0's l1: 59.07\n",
      "[550]\tvalid_0's l1: 58.6156\n",
      "[600]\tvalid_0's l1: 58.1861\n",
      "[650]\tvalid_0's l1: 58.2365\n",
      "[700]\tvalid_0's l1: 58.4096\n",
      "[750]\tvalid_0's l1: 58.3632\n",
      "[800]\tvalid_0's l1: 58.4112\n",
      "[850]\tvalid_0's l1: 58.275\n",
      "[900]\tvalid_0's l1: 59.15\n",
      "[950]\tvalid_0's l1: 58.9617\n",
      "[1000]\tvalid_0's l1: 58.808\n",
      "Early stopping, best iteration is:\n",
      "[833]\tvalid_0's l1: 58.0588\n",
      "Retrain valid MAE: 58.0416 | best_iter=833 | Δ=-4.9415\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 12: Retrain with selected features (HOTFIX) =====\n",
    "final_feats = [c for c in feature_cols if c not in drop_feats]\n",
    "\n",
    "X_tr2 = df_tr.loc[mask_day_tr, final_feats].fillna(0)\n",
    "y_tr2 = y_tr.values.astype(\"float32\")\n",
    "X_va2 = df_va.loc[:, final_feats].fillna(0)\n",
    "y_va2 = y_va.values.astype(\"float32\")\n",
    "\n",
    "model2 = lgb.LGBMRegressor(**params)\n",
    "\n",
    "callbacks2 = [\n",
    "    lgb.early_stopping(stopping_rounds=200),\n",
    "    lgb.log_evaluation(period=50)\n",
    "]\n",
    "\n",
    "model2.fit(\n",
    "    X_tr2, y_tr2,\n",
    "    eval_set=[(X_va2, y_va2)],\n",
    "    callbacks=callbacks2\n",
    ")\n",
    "\n",
    "best_iter2 = getattr(model2, \"best_iteration_\", None)\n",
    "pred_va2 = np.maximum(model2.predict(X_va2, num_iteration=best_iter2), 0.0)\n",
    "mae2 = mean_absolute_error(y_va2, pred_va2)\n",
    "print(f\"Retrain valid MAE: {mae2:.4f} | best_iter={best_iter2} | Δ={mae2 - mae0:+.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d004867-8deb-4d03-b30d-38842f28a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./result_submission.csv (2838240, 4) | null nins: 0\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 13 (HOTFIX): Build test features & predict with TZ-safe merge =====\n",
    "X_te = test.loc[:, final_feats].fillna(0)\n",
    "best_iter2 = getattr(model2, \"best_iteration_\", None)\n",
    "pred_te = np.maximum(model2.predict(X_te, num_iteration=best_iter2), 0.0).astype(\"float32\")\n",
    "\n",
    "sub = pd.read_csv(os.path.join(DATA_DIR, \"submission_sample.csv\"))\n",
    "\n",
    "# 머지 키 후보\n",
    "merge_keys = [c for c in [\"time\",\"pv_id\",\"type\"] if c in sub.columns and c in test.columns]\n",
    "\n",
    "def normalize_time_key_inplace(df: pd.DataFrame, col: str = \"time\"):\n",
    "    if col in df.columns:\n",
    "        # 1) 문자열/object -> datetime\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\", utc=False)\n",
    "        # 2) tz-aware면 KST로 변환 후 tz 제거(naive)\n",
    "        try:\n",
    "            if pd.api.types.is_datetime64tz_dtype(df[col].dtype):\n",
    "                df[col] = df[col].dt.tz_convert(\"Asia/Seoul\").dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            # dtype 체크 실패 시 .dt.tz 존재 여부로 방어\n",
    "            if getattr(df[col].dt, \"tz\", None) is not None:\n",
    "                df[col] = df[col].dt.tz_convert(\"Asia/Seoul\").dt.tz_localize(None)\n",
    "        # 3) 여전히 tz-naive가 아니면 최후 수단으로 문자열 통일\n",
    "        if pd.api.types.is_object_dtype(df[col].dtype):\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "# 1) test 쪽 time을 tz-naive로\n",
    "if \"time\" in test.columns:\n",
    "    test = test.copy()\n",
    "    test[\"time\"] = ensure_kst_series(test[\"time\"])  # KST로 맞추고 tz 제거\n",
    "\n",
    "# 2) sub 쪽 time을 tz-naive로\n",
    "if \"time\" in sub.columns:\n",
    "    sub = sub.copy()\n",
    "    normalize_time_key_inplace(sub, \"time\")\n",
    "\n",
    "if merge_keys:\n",
    "    # 키 정합성 빠른 경로: 키가 완전히 동일하면 인덱스 대입\n",
    "    left_keys  = sub[merge_keys].copy()\n",
    "    right_keys = test[merge_keys].copy()\n",
    "    # time이 있으면 양쪽 모두 tz-naive인지 재확인 (안전)\n",
    "    if \"time\" in merge_keys:\n",
    "        left_keys[\"time\"]  = pd.to_datetime(left_keys[\"time\"],  errors=\"coerce\")\n",
    "        right_keys[\"time\"] = pd.to_datetime(right_keys[\"time\"], errors=\"coerce\")\n",
    "\n",
    "    if left_keys.equals(right_keys):\n",
    "        out = sub.copy()\n",
    "        out[\"nins\"] = pred_te\n",
    "    else:\n",
    "        # 타입 불일치 방지: object vs datetime 충돌 방어\n",
    "        # 시간 키가 있으면 둘 다 문자열 포맷으로 통일 후 병합\n",
    "        lk = left_keys.copy()\n",
    "        rk = right_keys.copy()\n",
    "        if \"time\" in merge_keys:\n",
    "            fmt = \"%Y-%m-%d %H:%M:%S\"\n",
    "            lk[\"time\"] = pd.to_datetime(lk[\"time\"], errors=\"coerce\").dt.strftime(fmt)\n",
    "            rk[\"time\"] = pd.to_datetime(rk[\"time\"], errors=\"coerce\").dt.strftime(fmt)\n",
    "\n",
    "        ref = rk.copy()\n",
    "        ref[\"nins\"] = pred_te\n",
    "        # sub의 키도 동일 포맷으로 치환\n",
    "        sub_merge = sub.copy()\n",
    "        if \"time\" in merge_keys:\n",
    "            sub_merge[\"time\"] = lk[\"time\"]\n",
    "\n",
    "        out = safe_merge(sub_merge.drop(columns=[\"nins\"], errors=\"ignore\"), ref, on=merge_keys, how=\"left\")\n",
    "else:\n",
    "    # 병합 키가 없으면 순서가 동일하다고 가정하고 바로 대입\n",
    "    out = sub.copy()\n",
    "    out[\"nins\"] = pred_te\n",
    "\n",
    "out[\"nins\"] = out[\"nins\"].fillna(0).clip(lower=0).astype(\"float32\")\n",
    "out.to_csv(SAVE_SUB, index=False)\n",
    "print(\"Saved:\", SAVE_SUB, out.shape, \"| null nins:\", int(out[\"nins\"].isna().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3bd052e-cf33-4c71-b414-a773b2b24280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G0h</td>\n",
       "      <td>6.857763e+07</td>\n",
       "      <td>4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>humidity</td>\n",
       "      <td>2.486824e+07</td>\n",
       "      <td>17431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elev_sin</td>\n",
       "      <td>1.033187e+07</td>\n",
       "      <td>7376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>precip_3h_sum</td>\n",
       "      <td>6.978170e+06</td>\n",
       "      <td>4777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AM</td>\n",
       "      <td>6.305032e+06</td>\n",
       "      <td>3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>temp_a</td>\n",
       "      <td>5.428024e+06</td>\n",
       "      <td>18741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>doy</td>\n",
       "      <td>4.964510e+06</td>\n",
       "      <td>12935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dy_cos1</td>\n",
       "      <td>4.858070e+06</td>\n",
       "      <td>9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hr_cos1</td>\n",
       "      <td>4.166779e+06</td>\n",
       "      <td>1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ground_press</td>\n",
       "      <td>4.069883e+06</td>\n",
       "      <td>15112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dy_sin1</td>\n",
       "      <td>4.069809e+06</td>\n",
       "      <td>10898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wind_spd_a</td>\n",
       "      <td>2.852750e+06</td>\n",
       "      <td>16769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hour</td>\n",
       "      <td>2.839630e+06</td>\n",
       "      <td>5927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wind_dir_a</td>\n",
       "      <td>2.506976e+06</td>\n",
       "      <td>10900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rain</td>\n",
       "      <td>2.468127e+06</td>\n",
       "      <td>4237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wind_gust_spd</td>\n",
       "      <td>2.234662e+06</td>\n",
       "      <td>14232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wind_dir_a_sin</td>\n",
       "      <td>1.791195e+06</td>\n",
       "      <td>10779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wind_spd_b</td>\n",
       "      <td>1.511437e+06</td>\n",
       "      <td>11795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wind_dir_a_cos</td>\n",
       "      <td>1.500261e+06</td>\n",
       "      <td>9481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wind_dir_b</td>\n",
       "      <td>8.211936e+05</td>\n",
       "      <td>7174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature          gain  split\n",
       "11             G0h  6.857763e+07   4912\n",
       "4         humidity  2.486824e+07  17431\n",
       "9         elev_sin  1.033187e+07   7376\n",
       "12   precip_3h_sum  6.978170e+06   4777\n",
       "10              AM  6.305032e+06   3577\n",
       "6           temp_a  5.428024e+06  18741\n",
       "14             doy  4.964510e+06  12935\n",
       "18         dy_cos1  4.858070e+06   9477\n",
       "16         hr_cos1  4.166779e+06   1684\n",
       "3     ground_press  4.069883e+06  15112\n",
       "17         dy_sin1  4.069809e+06  10898\n",
       "8       wind_spd_a  2.852750e+06  16769\n",
       "13            hour  2.839630e+06   5927\n",
       "7       wind_dir_a  2.506976e+06  10900\n",
       "5             rain  2.468127e+06   4237\n",
       "1    wind_gust_spd  2.234662e+06  14232\n",
       "19  wind_dir_a_sin  1.791195e+06  10779\n",
       "2       wind_spd_b  1.511437e+06  11795\n",
       "20  wind_dir_a_cos  1.500261e+06   9481\n",
       "0       wind_dir_b  8.211936e+05   7174"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Cell 14: Inspect feature importances =====\n",
    "imp2 = pd.DataFrame({\n",
    "    \"feature\": final_feats,\n",
    "    \"gain\": model2.booster_.feature_importance(importance_type=\"gain\"),\n",
    "    \"split\": model2.booster_.feature_importance(importance_type=\"split\"),\n",
    "}).sort_values(\"gain\", ascending=False)\n",
    "imp2.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759359f1-4dc3-4d8e-9260-1c6d472a8232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
