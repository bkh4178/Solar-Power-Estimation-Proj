{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b96413-f5e5-4279-8b99-2ef941a859be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final feature count: 20\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 1 â€” Imports & Global Config\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# âœ… ìµœì¢… ì‚¬ìš©í•  Feature (20ê°œ)\n",
    "final_feats = [\n",
    "    'humidity', 'wind_gust_spd', 'hour', 'doy', 'wind_spd_b',\n",
    "    'ceiling', 'uv_idx', 'appr_temp', 'uv_cloud_adj', 'dow',\n",
    "    'hour_sin', 'doy_sin', 'is_rain', 'rain', 'hour_cos',\n",
    "    'doy_cos', 'snow', 'coord1', 'coord2', 'haze'\n",
    "]\n",
    "target_col = \"nins\"\n",
    "\n",
    "# ë³´ê°„ íŒŒë¼ë¯¸í„°(5ë¶„ ê°„ê²© ê¸°ì¤€ 12ì¹¸=1ì‹œê°„)\n",
    "MAX_GAP = 12  # ì—°ì† ê²°ì† í—ˆìš© ê¸¸ì´\n",
    "DAY_HOURS = (6, 18)  # ì£¼ê°„ í”„ë¡ì‹œ\n",
    "print(\"âœ… Final feature count:\", len(final_feats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cef59b-319a-4d99-9e02-f00785a740a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Step 2 â€” Feature Engineering: add_features()\n",
    "# ==============================================\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    EPS = 1e-6\n",
    "    out = df.copy()\n",
    "\n",
    "    # time\n",
    "    if not np.issubdtype(out[\"time\"].dtype, np.datetime64):\n",
    "        out[\"time\"] = pd.to_datetime(out[\"time\"])\n",
    "\n",
    "    # ì‹œê°„ íŒŒìƒ\n",
    "    out[\"hour\"] = out[\"time\"].dt.hour.astype(\"int16\")\n",
    "    out[\"dow\"]  = out[\"time\"].dt.dayofweek.astype(\"int16\")\n",
    "    out[\"doy\"]  = out[\"time\"].dt.dayofyear.astype(\"int16\")\n",
    "    out[\"hour_sin\"] = np.sin(2*np.pi*out[\"hour\"]/24).astype(\"float32\")\n",
    "    out[\"hour_cos\"] = np.cos(2*np.pi*out[\"hour\"]/24).astype(\"float32\")\n",
    "    out[\"doy_sin\"]  = np.sin(2*np.pi*out[\"doy\"]/365).astype(\"float32\")\n",
    "    out[\"doy_cos\"]  = np.cos(2*np.pi*out[\"doy\"]/365).astype(\"float32\")\n",
    "\n",
    "    # ê°•ìˆ˜ ì—¬ë¶€ (ê·œì¹™ ê¸°ë°˜)\n",
    "    if \"precip_1h\" in out.columns:\n",
    "        out[\"is_rain\"] = (pd.to_numeric(out[\"precip_1h\"], errors=\"coerce\").fillna(0) > 0).astype(\"int8\")\n",
    "    elif \"rain\" in out.columns:\n",
    "        out[\"is_rain\"] = (pd.to_numeric(out[\"rain\"], errors=\"coerce\").fillna(0) > 0).astype(\"int8\")\n",
    "    else:\n",
    "        out[\"is_rain\"] = 0\n",
    "\n",
    "    # haze (ê°€ì‹œê±°ë¦¬ ì—­ìˆ˜)\n",
    "    if \"vis\" in out.columns:\n",
    "        vis = pd.to_numeric(out[\"vis\"], errors=\"coerce\").astype(\"float32\")\n",
    "        out[\"haze\"] = (1.0 / (vis + EPS)).astype(\"float32\")\n",
    "    else:\n",
    "        out[\"haze\"] = 0.0\n",
    "\n",
    "    # ì¢Œí‘œ/ì‹ë³„ì ë©”ëª¨ë¦¬ ê²½ê°\n",
    "    if \"pv_id\" in out.columns and not pd.api.types.is_categorical_dtype(out[\"pv_id\"]):\n",
    "        out[\"pv_id\"] = out[\"pv_id\"].astype(\"category\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dbbedd-dbcd-4467-8aed-18c805471d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Step 3 â€” Physics-aware Interpolation (memory-light)\n",
    "#  - ì—°ì†í˜•: pvë³„ ì„ í˜• ë³´ê°„(<= MAX_GAP), ì”ì—¬ëŠ” (pv,hour)->pv->ì „ì²´ ì¤‘ì•™ê°’\n",
    "#  - ì´ì‚°í˜•: ì§§ê²Œ ffill/bfill (ë³´ê°„ ê¸ˆì§€)\n",
    "#  - uv_idx: ì£¼ê°„ë§Œ ë³´ê°„, ì•¼ê°„=0 ìœ ì§€\n",
    "#  - rain/snow: ë³´ê°„ ê¸ˆì§€(ê²°ì¸¡ì€ 0, í´ë¦¬í•‘ë§Œ)\n",
    "#  - ë³´ê°„ í›„ uv_cloud_adj ì¬ê³„ì‚°\n",
    "# ==============================================\n",
    "def interpolate_weather(df: pd.DataFrame, max_gap: int = MAX_GAP) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # ì£¼ê°„ ë§ˆìŠ¤í¬\n",
    "    day_mask = out[\"hour\"].between(DAY_HOURS[0], DAY_HOURS[1])\n",
    "\n",
    "    # ---- ì´ì‚°/ì´ë²¤íŠ¸í˜•: ë³´ê°„ ê¸ˆì§€, ì§§ì€ ê²°ì†ë§Œ ì•ë’¤ë¡œ ë©”ì›€ ----\n",
    "    if \"is_rain\" in out.columns:\n",
    "        s = out[\"is_rain\"].astype(\"float32\")\n",
    "        # pvë‹¨ìœ„ë¡œ ì§§ê²Œ ì•/ë’¤ ì±„ìš°ê¸°\n",
    "        s = out.groupby(\"pv_id\", observed=True)[\"is_rain\"].transform(\n",
    "            lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        ).astype(\"float32\")\n",
    "        # ë‚¨ì€ NaNì€ ì¤‘ì•™ê°’ìœ¼ë¡œ ë‹¨ê³„ì  ì±„ì›€\n",
    "        if s.isna().any():\n",
    "            s = s.fillna(out.groupby([\"pv_id\",\"hour\"], observed=True)[\"is_rain\"].transform(\"median\"))\n",
    "        if s.isna().any():\n",
    "            s = s.fillna(out.groupby(\"pv_id\", observed=True)[\"is_rain\"].transform(\"median\"))\n",
    "        if s.isna().any():\n",
    "            s = s.fillna(0)\n",
    "        out[\"is_rain\"] = s.astype(\"float32\")\n",
    "\n",
    "    # ---- ì—°ì†í˜•: ì„ í˜• ë³´ê°„ + ì¤‘ì•™ê°’ ë°±ì—… ----\n",
    "    cont_cols = [c for c in [\n",
    "        \"humidity\", \"wind_spd_b\", \"wind_gust_spd\", \"ceiling\", \"appr_temp\", \"uv_idx\", \"haze\"\n",
    "    ] if c in out.columns]\n",
    "\n",
    "    for c in cont_cols:\n",
    "        s = pd.to_numeric(out[c], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "        # uv_idxëŠ” ì£¼ê°„ë§Œ ë³´ê°„, ì•¼ê°„ì€ 0 ìœ ì§€\n",
    "        if c == \"uv_idx\":\n",
    "            s = s.where(day_mask, 0.0)\n",
    "\n",
    "        # pvë³„ ì„ í˜• ë³´ê°„ (ì—°ì† ê²°ì† ì œí•œ)\n",
    "        s_lin = out.groupby(\"pv_id\", observed=True)[c].transform(\n",
    "            lambda x: x.interpolate(method=\"linear\", limit=max_gap, limit_direction=\"both\")\n",
    "        ).astype(\"float32\")\n",
    "\n",
    "        # ì”ì—¬ ê²°ì¸¡ ë‹¨ê³„ì  ëŒ€ì²´: (pv,hour) â†’ pv â†’ ì „ì²´\n",
    "        if s_lin.isna().any():\n",
    "            s_lin = s_lin.fillna(out.groupby([\"pv_id\",\"hour\"], observed=True)[c].transform(\"median\"))\n",
    "        if s_lin.isna().any():\n",
    "            s_lin = s_lin.fillna(out.groupby(\"pv_id\", observed=True)[c].transform(\"median\"))\n",
    "        if s_lin.isna().any():\n",
    "            s_lin = s_lin.fillna(s_lin.median())\n",
    "\n",
    "        out[c] = s_lin.astype(\"float32\")\n",
    "\n",
    "    # ---- rain/snow: ë³´ê°„í•˜ì§€ ì•Šê³  0ìœ¼ë¡œ ìµœì†Œ ëŒ€ì²´ + ë¬¼ë¦¬ í´ë¦½ ----\n",
    "    for c in [\"rain\", \"snow\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\").fillna(0).clip(lower=0).astype(\"float32\")\n",
    "\n",
    "    # ---- ë¬¼ë¦¬ ë²”ìœ„ í´ë¦½ ----\n",
    "    clip_map = {\n",
    "        \"humidity\": (0, 100),\n",
    "        \"uv_idx\":   (0, None),\n",
    "        \"wind_spd_b\": (0, None),\n",
    "        \"wind_gust_spd\": (0, None),\n",
    "        \"ceiling\": (0, None),\n",
    "        \"appr_temp\": (None, None),  # ì˜¨ë„ëŠ” ìŒìˆ˜ ê°€ëŠ¥\n",
    "        \"haze\":    (0, None),\n",
    "        \"rain\":    (0, None),\n",
    "        \"snow\":    (0, None),\n",
    "    }\n",
    "    for c,(lo,hi) in clip_map.items():\n",
    "        if c in out.columns:\n",
    "            x = out[c].astype(\"float32\")\n",
    "            if lo is not None: x = np.maximum(x, lo)\n",
    "            if hi is not None: x = np.minimum(x, hi)\n",
    "            out[c] = x.astype(\"float32\")\n",
    "\n",
    "    # ---- uv_cloud_adj ì¬ê³„ì‚° ----\n",
    "    EPS = 1e-6\n",
    "    if \"uv_idx\" in out.columns:\n",
    "        if \"cloud_a\" in out.columns:\n",
    "            cloud_a_norm = pd.to_numeric(out[\"cloud_a\"], errors=\"coerce\").astype(\"float32\")\n",
    "            cloud_a_norm = cloud_a_norm / (float(cloud_a_norm.max()) + EPS)\n",
    "            out[\"uv_cloud_adj\"] = (out[\"uv_idx\"] * (1 - cloud_a_norm)).astype(\"float32\")\n",
    "        else:\n",
    "            out[\"uv_cloud_adj\"] = out[\"uv_idx\"].astype(\"float32\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6971c66d-2e46-4b4f-988a-e79221fc9f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Loading train & test CSVs ...\n",
      "âœ… Raw shapes â€” Train: (19236948, 33) | Test: (2838240, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_2508\\2553948729.py:37: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if \"pv_id\" in out.columns and not pd.api.types.is_categorical_dtype(out[\"pv_id\"]):\n",
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_2508\\2553948729.py:37: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if \"pv_id\" in out.columns and not pd.api.types.is_categorical_dtype(out[\"pv_id\"]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Dropped 0 rows with NaN target\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 4 â€” Load CSVs & Basic FE (train/test ê³µí†µ)\n",
    "# (ì—¬ê¸°ì„œëŠ” ì•„ì§ ë³´ê°„í•˜ì§€ ì•ŠìŒ)\n",
    "# ==============================================\n",
    "print(\"ğŸš€ Loading train & test CSVs ...\")\n",
    "train_raw = pd.read_csv(\"train.csv\", low_memory=True, memory_map=True)\n",
    "test_raw  = pd.read_csv(\"test.csv\",  low_memory=True, memory_map=True)\n",
    "print(f\"âœ… Raw shapes â€” Train: {train_raw.shape} | Test: {test_raw.shape}\")\n",
    "\n",
    "train_raw = add_features(train_raw)\n",
    "test_raw  = add_features(test_raw)\n",
    "\n",
    "# íƒ€ê¹ƒ ì •ì œ\n",
    "train_raw[target_col] = pd.to_numeric(train_raw[target_col], errors=\"coerce\").astype(\"float32\")\n",
    "before = len(train_raw)\n",
    "train_raw = train_raw.dropna(subset=[target_col])  # íƒ€ê¹ƒ ê²°ì¸¡ í–‰ ì œê±°\n",
    "print(f\"ğŸ”§ Dropped {before - len(train_raw)} rows with NaN target\")\n",
    "\n",
    "# ì°¸ê³ : pv_idê°€ ì¹´í…Œê³ ë¦¬ì´ë©´ groupbyê°€ ë©”ëª¨ë¦¬ì ìœ¼ë¡œ ìœ ë¦¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddb8089-9b6e-4f58-a441-c241d8e50076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_2508\\2293674040.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_2508\\2293674040.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Split OK â€” train: (15389558, 20), valid: (3847390, 20)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 5 â€” Validation Split (ëˆ„ìˆ˜ ë°©ì§€: split í›„ ê° ì„¸íŠ¸ë³„ ë³´ê°„)\n",
    "# ==============================================\n",
    "# ë¹ ë¥´ê³  ê³µì •í•˜ê²Œ: ëœë¤ 80/20 (ì‹œê°„ê¸°ë°˜ splitì´ í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ ë³€ê²½)\n",
    "train_df, valid_df = train_test_split(train_raw, test_size=0.2, random_state=42)\n",
    "\n",
    "# ê° ì„¸íŠ¸ì— ë³´ê°„ ì ìš© (ëˆ„ìˆ˜ ë°©ì§€)\n",
    "train_df = interpolate_weather(train_df, max_gap=MAX_GAP)\n",
    "valid_df = interpolate_weather(valid_df, max_gap=MAX_GAP)\n",
    "\n",
    "# ë³´ê°„ í›„ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ + NaN ìµœì†Œ ëŒ€ì²´\n",
    "train_df = train_df[[c for c in (final_feats + [target_col]) if c in train_df.columns]].copy()\n",
    "valid_df = valid_df[[c for c in (final_feats + [target_col]) if c in valid_df.columns]].copy()\n",
    "train_df[final_feats] = train_df[final_feats].astype(\"float32\").fillna(0)\n",
    "valid_df[final_feats] = valid_df[final_feats].astype(\"float32\").fillna(0)\n",
    "\n",
    "X_tr, y_tr = train_df[final_feats], train_df[target_col].values\n",
    "X_va, y_va = valid_df[final_feats], valid_df[target_col].values\n",
    "print(\"âœ… Split OK â€”\",\n",
    "      f\"train: {X_tr.shape}, valid: {X_va.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdf0283-1cd0-4983-a904-14a9ada5fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Training (validation monitoring, xgb.train)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [18:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:234.29114\tvalid-mae:234.28447\n",
      "[200]\ttrain-mae:56.35419\tvalid-mae:56.42220\n",
      "[400]\ttrain-mae:50.55834\tvalid-mae:50.72692\n",
      "[600]\ttrain-mae:47.97147\tvalid-mae:48.24526\n",
      "[800]\ttrain-mae:46.37048\tvalid-mae:46.76184\n",
      "[1000]\ttrain-mae:45.25604\tvalid-mae:45.76801\n",
      "[1200]\ttrain-mae:44.33219\tvalid-mae:44.96095\n",
      "[1400]\ttrain-mae:43.66895\tvalid-mae:44.41604\n",
      "[1600]\ttrain-mae:43.09167\tvalid-mae:43.95540\n",
      "[1800]\ttrain-mae:42.61004\tvalid-mae:43.59123\n",
      "[2000]\ttrain-mae:42.20379\tvalid-mae:43.30632\n",
      "[2200]\ttrain-mae:41.80140\tvalid-mae:43.02401\n",
      "[2400]\ttrain-mae:41.44102\tvalid-mae:42.78333\n",
      "[2600]\ttrain-mae:41.13248\tvalid-mae:42.59495\n",
      "[2800]\ttrain-mae:40.86829\tvalid-mae:42.44955\n",
      "[2999]\ttrain-mae:40.60675\tvalid-mae:42.30848\n",
      "âœ… Best iteration: 2998 | Validation MAE: 42.3085\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 1) DMatrixë¡œ ë³€í™˜\n",
    "dtrain = xgb.DMatrix(X_tr, label=y_tr, feature_names=X_tr.columns.tolist())\n",
    "dvalid = xgb.DMatrix(X_va, label=y_va, feature_names=X_va.columns.tolist())\n",
    "\n",
    "# 2) íŒŒë¼ë¯¸í„° (GPU ì“°ë©´ 'gpu_hist'ë¡œ)\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"mae\",          # <- MAE ëª¨ë‹ˆí„°ë§\n",
    "    \"learning_rate\": 0.06,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_weight\": 4,\n",
    "    \"subsample\": 0.75,\n",
    "    \"colsample_bytree\": 0.85,\n",
    "    'reg_alpha': 0.3,\n",
    "     'reg_lambda': 0.6,\n",
    "     'random_state': 42,\n",
    "     'n_estimators': 3790}\n",
    "\n",
    "print(\"ğŸš€ Training (validation monitoring, xgb.train)...\")\n",
    "evals = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=3000,              # í¬ê²Œ ì‹œì‘\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=200,         # ì–¼ë¦¬ ìŠ¤í†± OK\n",
    "    verbose_eval=200                   # 200ë¼ìš´ë“œë§ˆë‹¤ ë¡œê·¸\n",
    ")\n",
    "\n",
    "best_n = booster.best_iteration + 1     # best_iterationì€ 0-based\n",
    "pred_va = booster.predict(dvalid, iteration_range=(0, booster.best_iteration + 1))\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = mean_absolute_error(y_va, pred_va)\n",
    "print(f\"âœ… Best iteration: {best_n} | Validation MAE: {val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75582ae-b7c3-4ba6-b4a9-fddb67d86b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_2508\\2293674040.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Full-data training with num_boost_round=3597 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:27:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved â†’ xgb_full_final.json\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 7 â€” Full-data Training (xgboost.train, Booster ì €ì¥)\n",
    "#  * ì „ì²´ train_rawì— ë™ì¼ ë³´ê°„ ê·œì¹™ ì ìš©\n",
    "#  * num_boost_round = max(1200, int(best_n*1.2))\n",
    "#  * paramsëŠ” Step 6ê³¼ ë™ì¼(ì—†ìœ¼ë©´ ì•„ë˜ì—ì„œ ê¸°ë³¸ì…‹ ì§€ì •)\n",
    "# ==============================================\n",
    "import xgboost as xgb\n",
    "\n",
    "# paramsê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° ëŒ€ë¹„(í•„ìš” ì‹œ GPUë¡œ ë³€ê²½: tree_method=\"gpu_hist\")\n",
    "if \"params\" not in globals():\n",
    "    params = {'objective': 'reg:squarederror',\n",
    " 'eval_metric': 'mae',\n",
    " 'learning_rate': 0.06,\n",
    " 'max_depth': 9,\n",
    " 'min_child_weight': 4,\n",
    " 'subsample': 0.75,\n",
    " 'colsample_bytree': 0.85,\n",
    " 'reg_alpha': 0.3,\n",
    " 'reg_lambda': 0.6,\n",
    " 'random_state': 42,\n",
    " 'n_estimators': 3790}\n",
    "\n",
    "# 1) ì „ì²´ ë³´ê°„\n",
    "train_full = interpolate_weather(train_raw, max_gap=MAX_GAP)\n",
    "\n",
    "# 2) í”¼ì²˜ ì„ íƒ/ì •ë¦¬\n",
    "use_cols = [c for c in (final_feats + [target_col]) if c in train_full.columns]\n",
    "train_full = train_full[use_cols].copy()\n",
    "train_full[final_feats] = train_full[final_feats].astype(\"float32\").fillna(0)\n",
    "\n",
    "X_full = train_full[final_feats]\n",
    "y_full = train_full[target_col].values\n",
    "\n",
    "# 3) DMatrixë¡œ ë³€í™˜\n",
    "dfull = xgb.DMatrix(X_full, label=y_full, feature_names=final_feats)\n",
    "\n",
    "# 4) Full í•™ìŠµ\n",
    "num_boost_round = max(1200, int(best_n * 1.2)) if \"best_n\" in globals() else 1500\n",
    "print(f\"\\nğŸš€ Full-data training with num_boost_round={num_boost_round} ...\")\n",
    "\n",
    "final_booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dfull,\n",
    "    num_boost_round=num_boost_round,\n",
    "    verbose_eval=200\n",
    ")\n",
    "\n",
    "# 5) ëª¨ë¸ ì €ì¥ (Booster í˜•ì‹)\n",
    "final_booster.save_model(\"xgb_full_final.json\")\n",
    "print(\"ğŸ’¾ Saved â†’ xgb_full_final.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d07ee5-ec69-4859-a8b7-bf0e1a58d8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_2508\\2293674040.py:20: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Inference on test set ...\n",
      "ğŸŒ™ night clamp applied: 1,444,691 rows set to 0\n",
      "âœ… Test prediction complete | min=0.0000, max=1264.3934\n",
      "ğŸ”— Applied direct assignment (len match).\n",
      "ğŸ’¾ Saved â†’ result_submission.csv\n",
      "nins null before fill: 0 | after fill: 0\n",
      "pred stats: 0.0 1264.3934326171875 193.4229278564453 288.3812561035156\n",
      "\n",
      "âœ… Submission preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pv_id</th>\n",
       "      <th>type</th>\n",
       "      <th>nins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-01 00:05:00+09:00</td>\n",
       "      <td>PV_ID_7</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-01 00:10:00+09:00</td>\n",
       "      <td>PV_ID_7</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-01 00:15:00+09:00</td>\n",
       "      <td>PV_ID_7</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-01 00:20:00+09:00</td>\n",
       "      <td>PV_ID_7</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-01 00:25:00+09:00</td>\n",
       "      <td>PV_ID_7</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time    pv_id  type  nins\n",
       "0  2024-08-01 00:05:00+09:00  PV_ID_7  test   0.0\n",
       "1  2024-08-01 00:10:00+09:00  PV_ID_7  test   0.0\n",
       "2  2024-08-01 00:15:00+09:00  PV_ID_7  test   0.0\n",
       "3  2024-08-01 00:20:00+09:00  PV_ID_7  test   0.0\n",
       "4  2024-08-01 00:25:00+09:00  PV_ID_7  test   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 8 â€” Test Interp + Predict(Booster) + Night Clamp + Save\n",
    "#  * í…œí”Œë¦¿ íŒŒì¼ëª…: submission_sample.csv (í•„ìš”ì‹œ ë°”ê¿”ë„ OK)\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "SUB_FILE = \"submission_sample.csv\"   # â† ë„¤ íŒŒì¼ëª…ì— ë§ì¶¤ (sample_submission.csvì´ë©´ ë°”ê¿”ë„ ë¨)\n",
    "\n",
    "# 1) test ë³´ê°„/ì •ë¦¬\n",
    "test_itp = interpolate_weather(test_raw, max_gap=MAX_GAP)\n",
    "test_itp = test_itp[[c for c in final_feats if c in test_itp.columns]].copy()\n",
    "test_itp[final_feats] = test_itp[final_feats].astype(\"float32\").fillna(0)\n",
    "\n",
    "# 2) ì˜ˆì¸¡ (Booster)\n",
    "dtest = xgb.DMatrix(test_itp[final_feats], feature_names=final_feats)\n",
    "print(\"\\nğŸš€ Inference on test set ...\")\n",
    "pred_test = final_booster.predict(dtest)\n",
    "pred_test = np.clip(pred_test.astype(\"float32\"), 0, None)\n",
    "\n",
    "# 3) Night clamp (uv_idx<=0 ë˜ëŠ” ì‹œê°„ëŒ€ ê¸°ì¤€)\n",
    "#    hour/uv_idxëŠ” test_itpì— ì¡´ì¬(íŒŒìƒ í¬í•¨). hour ê¸°ì¤€ 06~18 ì£¼ê°„ í”„ë¡ì‹œ.\n",
    "uv_zero   = (test_itp.get(\"uv_idx\", 0) <= 0)\n",
    "hour_mask = ~(test_itp.get(\"hour\", pd.Series([12]*len(test_itp))).between(6, 18))\n",
    "mask_night = (uv_zero | hour_mask).values\n",
    "pred_test[mask_night] = 0.0\n",
    "\n",
    "print(f\"ğŸŒ™ night clamp applied: {mask_night.sum():,} rows set to 0\")\n",
    "print(f\"âœ… Test prediction complete | min={pred_test.min():.4f}, max={pred_test.max():.4f}\")\n",
    "\n",
    "# 4) ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "sub = pd.read_csv(SUB_FILE)\n",
    "\n",
    "if len(sub) == len(pred_test):\n",
    "    sub[\"nins\"] = pred_test\n",
    "    out = sub\n",
    "    print(\"ğŸ”— Applied direct assignment (len match).\")\n",
    "else:\n",
    "    # í‚¤ ê¸°ë°˜ ë³‘í•©(ì•ˆì „)\n",
    "    merge_keys = [c for c in [\"time\",\"pv_id\",\"type\"] if c in sub.columns and c in test_raw.columns]\n",
    "    # timeì´ ë¬¸ìì—´/íƒ€ì… í˜¼ì„ ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ í†µì¼\n",
    "    for df_ in (sub, test_raw):\n",
    "        if \"time\" in df_.columns:\n",
    "            df_[\"time\"] = df_[\"time\"].astype(str)\n",
    "\n",
    "    ref = test_raw[merge_keys].copy()\n",
    "    ref[\"nins\"] = pred_test\n",
    "    ref = ref.drop_duplicates(subset=merge_keys, keep=\"last\")\n",
    "    out = sub.drop(columns=[\"nins\"], errors=\"ignore\").merge(ref, on=merge_keys, how=\"left\")\n",
    "    print(\"ğŸ”’ Applied key-based merge.\")\n",
    "\n",
    "# 5) ì €ì¥ ë° ì ê²€\n",
    "nan_before = int(out[\"nins\"].isna().sum())\n",
    "out[\"nins\"] = out[\"nins\"].fillna(0).astype(\"float32\")\n",
    "out.to_csv(\"result_submission.csv\", index=False)\n",
    "print(\"ğŸ’¾ Saved â†’ result_submission.csv\")\n",
    "print(f\"nins null before fill: {nan_before} | after fill: {int(out['nins'].isna().sum())}\")\n",
    "\n",
    "print(\"pred stats:\",\n",
    "      float(out[\"nins\"].min()), float(out[\"nins\"].max()),\n",
    "      float(out[\"nins\"].mean()), float(out[\"nins\"].std()))\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    print(\"\\nâœ… Submission preview:\")\n",
    "    display(out.head())\n",
    "except Exception:\n",
    "    print(out.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e49dba-486e-4f99-b8dc-07724375989d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
