{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a55fa5-4f80-4846-b713-dd9345eb2be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FINAL_FEATS: 20\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: Imports & Config ===\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "TIME_COL   = \"time\"\n",
    "PV_COL     = \"pv_id\"\n",
    "TARGET     = \"nins\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# âœ… ê³µì‹ ìµœì¢… í”¼ì²˜ 20ê°œ (ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "FINAL_FEATS = [\n",
    " 'humidity','wind_gust_spd','hour','doy','wind_spd_b',\n",
    " 'ceiling','uv_idx','appr_temp','uv_cloud_adj','dow',\n",
    " 'hour_sin','doy_sin','is_rain','rain','hour_cos',\n",
    " 'doy_cos','snow','coord1','coord2','haze'\n",
    "]\n",
    "\n",
    "MAX_GAP   = 12     # 5ë¶„ ê°„ê²© ê¸°ì¤€ 12ì¹¸ â‰ˆ 1ì‹œê°„\n",
    "DAY_HOURS = (6,18) # ì£¼ê°„ í”„ë¡ì‹œ(ë³´ê°„/í´ë¨í”„ì— ì‚¬ìš©)\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print(\"âœ… FINAL_FEATS:\", len(FINAL_FEATS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd67c20-d6e8-4aa7-a43b-31634bc16531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Time utils + time features ===\n",
    "def ensure_naive_datetime(s: pd.Series, tz=\"Asia/Seoul\") -> pd.Series:\n",
    "    if not is_datetime64_any_dtype(s):\n",
    "        s = pd.to_datetime(s, errors=\"coerce\", utc=True)\n",
    "    if isinstance(s.dtype, DatetimeTZDtype):\n",
    "        try:\n",
    "            s = s.dt.tz_convert(tz).dt.tz_localize(None)\n",
    "        except Exception:\n",
    "            s = s.dt.tz_localize(None)\n",
    "    return s\n",
    "\n",
    "def cyclical_encode(series: pd.Series, period: int):\n",
    "    angle = 2*np.pi*(series.astype(\"float32\") % period)/period\n",
    "    return np.sin(angle).astype(\"float32\"), np.cos(angle).astype(\"float32\")\n",
    "\n",
    "def add_time_features(df: pd.DataFrame, time_col=TIME_COL) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[time_col] = ensure_naive_datetime(out[time_col])\n",
    "    out[\"hour\"] = out[time_col].dt.hour.astype(\"int16\")\n",
    "    out[\"dow\"]  = out[time_col].dt.dayofweek.astype(\"int8\")\n",
    "    out[\"doy\"]  = out[time_col].dt.dayofyear.astype(\"int16\")\n",
    "    out[\"hour_sin\"], out[\"hour_cos\"] = cyclical_encode(out[\"hour\"], 24)\n",
    "    out[\"doy_sin\"],  out[\"doy_cos\"]  = cyclical_encode(out[\"doy\"], 365)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e315bc-00a2-4d01-bcf4-46b04133878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Feature wrapper (ensure 20 feats exist) ===\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = add_time_features(df)\n",
    "\n",
    "    # is_rain\n",
    "    if \"is_rain\" not in out.columns:\n",
    "        src = \"rain\" if \"rain\" in out.columns else None\n",
    "        out[\"is_rain\"] = (pd.to_numeric(out[src], errors=\"coerce\").fillna(0) > 0).astype(\"int8\") if src else np.int8(0)\n",
    "\n",
    "    # haze (ê°€ì‹œê±°ë¦¬ ì—­ìˆ˜ í˜•íƒœê°€ ì—†ìœ¼ë©´ 0)\n",
    "    if \"haze\" not in out.columns:\n",
    "        out[\"haze\"] = np.float32(0.0)\n",
    "\n",
    "    # uv_cloud_adj (í´ë¼ìš°ë“œ ì—†ìœ¼ë©´ uv_idxë¡œ ëŒ€ì²´)\n",
    "    if \"uv_cloud_adj\" not in out.columns:\n",
    "        out[\"uv_cloud_adj\"] = pd.to_numeric(out.get(\"uv_idx\", 0.0), errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    # pv_id ì¹´í…Œê³ ë¦¬(ë©”ëª¨ë¦¬â†“)\n",
    "    if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n",
    "        out[PV_COL] = out[PV_COL].astype(\"category\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124fbf5b-b252-4bd0-b632-3641d0a9dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Interpolation (physics-aware, memory-light) ===\n",
    "def interpolate_weather(df: pd.DataFrame, max_gap: int=MAX_GAP) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    day_mask = out[\"hour\"].between(DAY_HOURS[0], DAY_HOURS[1])\n",
    "\n",
    "    # ì´ë²¤íŠ¸í˜•: is_rain (ë³´ê°„ X, ì§§ì€ ê²°ì†ë§Œ ë³´ì™„)\n",
    "    if \"is_rain\" in out.columns:\n",
    "        s = pd.to_numeric(out[\"is_rain\"], errors=\"coerce\")\n",
    "        s = out.groupby(PV_COL, observed=True)[\"is_rain\"].transform(lambda x: x.ffill().bfill()).astype(\"float32\")\n",
    "        for lev in ([\"pv_id\",\"hour\"], [\"pv_id\"]):\n",
    "            if s.isna().any():\n",
    "                s = s.fillna(out.groupby(lev, observed=True)[\"is_rain\"].transform(\"median\"))\n",
    "        out[\"is_rain\"] = s.fillna(0).astype(\"float32\")\n",
    "\n",
    "    # ì—°ì†í˜•: ì„ í˜•ë³´ê°„(uvëŠ” ì£¼ê°„ë§Œ), ì”ì—¬ëŠ” (pv,hour)->pv->ì „ì²´ ì¤‘ì•™ê°’\n",
    "    cont_cols = [c for c in [\"humidity\",\"wind_spd_b\",\"wind_gust_spd\",\"ceiling\",\"appr_temp\",\"uv_idx\",\"haze\"] if c in out.columns]\n",
    "    for c in cont_cols:\n",
    "        s = pd.to_numeric(out[c], errors=\"coerce\").astype(\"float32\")\n",
    "        if c == \"uv_idx\":\n",
    "            s = s.where(day_mask, 0.0)\n",
    "        s_lin = out.groupby(PV_COL, observed=True)[c].transform(\n",
    "            lambda x: x.interpolate(method=\"linear\", limit=max_gap, limit_direction=\"both\")\n",
    "        ).astype(\"float32\")\n",
    "        if s_lin.isna().any():\n",
    "            s_lin = s_lin.fillna(out.groupby([PV_COL,\"hour\"], observed=True)[c].transform(\"median\"))\n",
    "        if s_lin.isna().any():\n",
    "            s_lin = s_lin.fillna(out.groupby(PV_COL, observed=True)[c].transform(\"median\"))\n",
    "        out[c] = s_lin.fillna(s_lin.median()).astype(\"float32\")\n",
    "\n",
    "    # rain/snow: ë³´ê°„ ì—†ì´ 0 ì±„ì›€ + ë¬¼ë¦¬ì  í´ë¦½\n",
    "    for c in [\"rain\",\"snow\"]:\n",
    "        if c in out.columns:\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\").fillna(0).clip(lower=0).astype(\"float32\")\n",
    "\n",
    "    # ë¬¼ë¦¬ ë²”ìœ„ í´ë¦½\n",
    "    clip_map = {\"humidity\":(0,100), \"uv_idx\":(0,None), \"wind_spd_b\":(0,None), \"wind_gust_spd\":(0,None),\n",
    "                \"ceiling\":(0,None), \"appr_temp\":(None,None), \"haze\":(0,None)}\n",
    "    for c,(lo,hi) in clip_map.items():\n",
    "        if c in out.columns:\n",
    "            x = out[c].astype(\"float32\")\n",
    "            if lo is not None: x = np.maximum(x, lo)\n",
    "            if hi is not None: x = np.minimum(x, hi)\n",
    "            out[c] = x.astype(\"float32\")\n",
    "\n",
    "    # uv_cloud_adj ê°±ì‹ (í´ë¼ìš°ë“œ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ)\n",
    "    if \"uv_idx\" in out.columns:\n",
    "        out[\"uv_cloud_adj\"] = pd.to_numeric(out.get(\"uv_cloud_adj\", out[\"uv_idx\"]), errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a46d56f-fa06-4a0d-a372-c3004c865274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train raw shape: (19236948, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_27572\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped NaN target rows: 0\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5: Load CSVs + basic FE ===\n",
    "train_raw = pd.read_csv(\"train.csv\", low_memory=True, memory_map=True)\n",
    "print(\"Train raw shape:\", train_raw.shape)\n",
    "train_raw = add_features(train_raw)\n",
    "\n",
    "# íƒ€ê¹ƒ ì •ì œ\n",
    "train_raw[TARGET] = pd.to_numeric(train_raw[TARGET], errors=\"coerce\").astype(\"float32\")\n",
    "before = len(train_raw); train_raw = train_raw.dropna(subset=[TARGET])\n",
    "print(f\"Dropped NaN target rows: {before - len(train_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9294192-52dc-4903-a0fd-be90af64c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split â†’ (15389558, 20) (3847390, 20)\n"
     ]
    }
   ],
   "source": [
    "# === Cell 6: Split â†’ Interp per set (no leakage) ===\n",
    "train_df, valid_df = train_test_split(train_raw, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "train_df = interpolate_weather(train_df, max_gap=MAX_GAP)\n",
    "valid_df = interpolate_weather(valid_df, max_gap=MAX_GAP)\n",
    "\n",
    "# í•„ìš”í•œ ì—´ë§Œ ì–‡ê²Œ + NaN 0 ëŒ€ì²´\n",
    "use_cols_tr = [c for c in (FINAL_FEATS + [TARGET]) if c in train_df.columns]\n",
    "use_cols_va = [c for c in (FINAL_FEATS + [TARGET]) if c in valid_df.columns]\n",
    "train_df = train_df[use_cols_tr].copy()\n",
    "valid_df = valid_df[use_cols_va].copy()\n",
    "train_df[FINAL_FEATS] = train_df[FINAL_FEATS].astype(\"float32\").fillna(0)\n",
    "valid_df[FINAL_FEATS] = valid_df[FINAL_FEATS].astype(\"float32\").fillna(0)\n",
    "\n",
    "X_tr, y_tr = train_df[FINAL_FEATS], train_df[TARGET].values\n",
    "X_va, y_va = valid_df[FINAL_FEATS], valid_df[TARGET].values\n",
    "print(\"Split â†’\", X_tr.shape, X_va.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13ac2e8-9d6a-4ab5-b5cd-6d67cb5e15bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Training...\n",
      "[0]\ttrain-mae:234.22506\tvalid-mae:234.21788\n",
      "[200]\ttrain-mae:55.90217\tvalid-mae:55.96908\n",
      "[400]\ttrain-mae:50.20126\tvalid-mae:50.36508\n",
      "[600]\ttrain-mae:47.59565\tvalid-mae:47.86759\n",
      "[800]\ttrain-mae:45.99632\tvalid-mae:46.39157\n",
      "[1000]\ttrain-mae:44.73640\tvalid-mae:45.25612\n",
      "[1200]\ttrain-mae:43.85012\tvalid-mae:44.48767\n",
      "[1400]\ttrain-mae:43.17632\tvalid-mae:43.93320\n",
      "[1600]\ttrain-mae:42.59860\tvalid-mae:43.47950\n",
      "[1800]\ttrain-mae:42.14130\tvalid-mae:43.13943\n",
      "[2000]\ttrain-mae:41.72985\tvalid-mae:42.84871\n",
      "[2200]\ttrain-mae:41.32850\tvalid-mae:42.56158\n",
      "[2400]\ttrain-mae:40.98554\tvalid-mae:42.33454\n",
      "[2600]\ttrain-mae:40.69290\tvalid-mae:42.15541\n",
      "[2800]\ttrain-mae:40.40587\tvalid-mae:41.97984\n",
      "[2999]\ttrain-mae:40.11851\tvalid-mae:41.80572\n",
      "âœ… Best iter=3000  |  VALID MAE=41.8057\n"
     ]
    }
   ],
   "source": [
    "# === Cell 7: Train with early stopping + VALID MAE ===\n",
    "dtr = xgb.DMatrix(X_tr, label=y_tr, feature_names=FINAL_FEATS)\n",
    "dva = xgb.DMatrix(X_va, label=y_va, feature_names=FINAL_FEATS)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"learning_rate\": 0.06,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_weight\": 4,\n",
    "    \"subsample\": 0.75,\n",
    "    \"colsample_bytree\": 0.85,\n",
    "    \"reg_alpha\": 0.3,\n",
    "    \"reg_lambda\": 0.6,\n",
    "    \"random_state\": RANDOM_SEED,\n",
    "    # í•„ìš”ì‹œ \"tree_method\": \"gpu_hist\"\n",
    "}\n",
    "\n",
    "print(\"ğŸš€ Training...\")\n",
    "bst = xgb.train(params, dtr, num_boost_round=3000,\n",
    "                evals=[(dtr,\"train\"), (dva,\"valid\")],\n",
    "                early_stopping_rounds=200, verbose_eval=200)\n",
    "\n",
    "best_n = bst.best_iteration + 1\n",
    "pred_va = bst.predict(dva, iteration_range=(0, bst.best_iteration+1)).astype(\"float32\")\n",
    "val_mae = mean_absolute_error(y_va, pred_va)\n",
    "print(f\"âœ… Best iter={best_n}  |  VALID MAE={val_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38a6da4-cb33-456f-bb3e-b5cfde4b14ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Full-data training with num_boost_round=3600 ...\n",
      "ğŸ’¾ Saved â†’ xgb_full_final.json\n"
     ]
    }
   ],
   "source": [
    "# === Cell F1: Full-data train (use best_n*1.2) ===\n",
    "# train_raw, FINAL_FEATS, interpolate_weather, params ê°€ ì• ì…€ì—ì„œ ì´ë¯¸ ì •ì˜ë¨\n",
    "\n",
    "train_full = interpolate_weather(train_raw, max_gap=MAX_GAP)\n",
    "use_cols = [c for c in (FINAL_FEATS + [TARGET]) if c in train_full.columns]\n",
    "train_full = train_full[use_cols].copy()\n",
    "train_full[FINAL_FEATS] = train_full[FINAL_FEATS].astype(\"float32\").fillna(0)\n",
    "\n",
    "dfull = xgb.DMatrix(train_full[FINAL_FEATS], label=train_full[TARGET].values, feature_names=FINAL_FEATS)\n",
    "\n",
    "num_round = 3600  # best_n(=3000) * 1.2\n",
    "print(f\"ğŸš€ Full-data training with num_boost_round={num_round} ...\")\n",
    "final_bst = xgb.train(params, dfull, num_boost_round=num_round, verbose_eval=300)\n",
    "final_bst.save_model(\"xgb_full_final.json\")\n",
    "print(\"ğŸ’¾ Saved â†’ xgb_full_final.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff7b420-9aeb-477f-9e8a-5320696de7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexs\\AppData\\Local\\Temp\\ipykernel_27572\\3110150134.py:19: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if PV_COL in out.columns and not pd.api.types.is_categorical_dtype(out[PV_COL]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: result_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell F2: Predict test + save submission ===\n",
    "TEST_CSV = \"test.csv\"\n",
    "SUB_CSV  = \"submission_sample.csv\" if os.path.exists(\"submission_sample.csv\") else \"sample_submission.csv\"\n",
    "\n",
    "test_raw = pd.read_csv(TEST_CSV, low_memory=True, memory_map=True)\n",
    "test_raw = add_features(test_raw)\n",
    "test_itp = interpolate_weather(test_raw, max_gap=MAX_GAP)\n",
    "\n",
    "# ì…ë ¥ ì •ë¦¬\n",
    "feat_exist = [c for c in FINAL_FEATS if c in test_itp.columns]\n",
    "test_mat = test_itp[feat_exist].astype(\"float32\").fillna(0)\n",
    "dte = xgb.DMatrix(test_mat, feature_names=feat_exist)\n",
    "\n",
    "# ì˜ˆì¸¡ + í´ë¦¬í•‘\n",
    "pred = final_bst.predict(dte).astype(\"float32\")\n",
    "pred = np.clip(pred, 0, None)\n",
    "\n",
    "# (ì„ íƒ) ì•¼ê°„ ë³´ìˆ˜ì  í´ë¨í”„: uv_idx<=0 ë˜ëŠ” ì‹œê°„ not in [6,18] â†’ 0\n",
    "if \"uv_idx\" in test_itp.columns and \"hour\" in test_raw.columns:\n",
    "    mask_night = (pd.to_numeric(test_itp[\"uv_idx\"], errors=\"coerce\") <= 0) | ~test_raw[\"hour\"].between(6,18)\n",
    "    pred[mask_night.values] = 0.0\n",
    "\n",
    "# ì œì¶œ í¬ë§· ë§ì¶”ê¸°\n",
    "sub = pd.read_csv(SUB_CSV)\n",
    "if len(sub) == len(pred):\n",
    "    sub[\"nins\"] = pred\n",
    "else:\n",
    "    merge_keys = [k for k in [\"time\",\"pv_id\",\"type\"] if k in sub.columns and k in test_raw.columns]\n",
    "    for df_ in (sub, test_raw):\n",
    "        if \"time\" in df_.columns:\n",
    "            df_[\"time\"] = pd.to_datetime(df_[\"time\"], errors=\"coerce\")\n",
    "    ref = test_raw[merge_keys].copy()\n",
    "    ref[\"nins\"] = pred\n",
    "    sub = sub.drop(columns=[\"nins\"], errors=\"ignore\").merge(ref, on=merge_keys, how=\"left\")\n",
    "\n",
    "sub[\"nins\"] = sub[\"nins\"].fillna(0).astype(\"float32\")\n",
    "sub.to_csv(\"result_submission.csv\", index=False)\n",
    "print(\"âœ… Saved: result_submission.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bca13c-fe67-4e4f-aae1-5b916c6270f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
